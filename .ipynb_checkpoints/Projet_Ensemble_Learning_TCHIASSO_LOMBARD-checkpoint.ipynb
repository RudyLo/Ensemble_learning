{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de données\n",
    "\n",
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('beer_quality.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "4     53\n",
       "8     18\n",
       "3     10\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données en features et label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  \n",
       "0         9.4  \n",
       "1         9.8  \n",
       "2         9.8  \n",
       "3         9.8  \n",
       "4         9.4  \n",
       "...       ...  \n",
       "1594     10.5  \n",
       "1595     11.2  \n",
       "1596     11.0  \n",
       "1597     10.2  \n",
       "1598     11.0  \n",
       "\n",
       "[1599 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       5\n",
       "2       5\n",
       "3       6\n",
       "4       5\n",
       "       ..\n",
       "1594    5\n",
       "1595    6\n",
       "1596    6\n",
       "1597    5\n",
       "1598    6\n",
       "Name: quality, Length: 1599, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données en train et en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Classification Binaire \n",
    "\n",
    "## Création de nouvelle variable en fonction de la médiane de y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "#Calcul de la médiane\n",
    "statistics.median(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implémentation de ybin en fonction de la médiane \n",
    "\n",
    "ybin = []\n",
    "\n",
    "for i in y:\n",
    "    m = 6\n",
    "    if i < m:\n",
    "        ybin.append(0)\n",
    "        \n",
    "    else:\n",
    "        ybin.append(1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df.assign(ybin= ybin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>ybin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  ybin  \n",
       "0         9.4        5     0  \n",
       "1         9.8        5     0  \n",
       "2         9.8        5     0  \n",
       "3         9.8        6     1  \n",
       "4         9.4        5     0  \n",
       "...       ...      ...   ...  \n",
       "1594     10.5        5     0  \n",
       "1595     11.2        6     1  \n",
       "1596     11.0        6     1  \n",
       "1597     10.2        5     0  \n",
       "1598     11.0        6     1  \n",
       "\n",
       "[1599 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>ybin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  ybin  \n",
       "0         9.4     0  \n",
       "1         9.8     0  \n",
       "2         9.8     0  \n",
       "3         9.8     1  \n",
       "4         9.4     0  \n",
       "...       ...   ...  \n",
       "1594     10.5     0  \n",
       "1595     11.2     1  \n",
       "1596     11.0     1  \n",
       "1597     10.2     0  \n",
       "1598     11.0     1  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On cherche à prédire ybin, on supprime quality\n",
    "new_df.drop(\"quality\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.iloc[:, :11]\n",
    "y = new_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc=StandardScaler()\n",
    "\n",
    "#scaler = sc.fit(X)\n",
    "#X = scaler.transform(X)\n",
    "\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth' : np.arange(1,5),\n",
    "             'min_samples_split' : np.arange (1,5)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(clf, param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [       nan 0.68721973 0.68721973 0.68721973        nan 0.68900545\n",
      " 0.68900545 0.68900545        nan 0.70418402 0.70418402 0.70418402\n",
      "        nan 0.72204917 0.72294202 0.72294202]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(criterion='entropy'),\n",
       "             param_grid={'max_depth': array([1, 2, 3, 4]),\n",
       "                         'min_samples_split': array([1, 2, 3, 4])})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73125"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 1\n",
    "model_a = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1), n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   n_estimators=100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7479166666666667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import pylab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = [10,20, 30, 40, 50, 60,70,80,90,100]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=n_estimators[i])\n",
    "\n",
    "    # Train Adaboost Classifer\n",
    "    model = bdt.fit(X_train, y_train)\n",
    "    accuracy_train.append(bdt.score(X_train, y_train))\n",
    "    accuracy_test.append(bdt.score(X_test, y_test))\n",
    "\n",
    "\n",
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = [10,20, 30, 40, 50, 60,70,80,90,100]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5), algorithm=\"SAMME\", n_estimators=n_estimators[i])\n",
    "\n",
    "    # Train Adaboost Classifer\n",
    "    model = bdt.fit(X_train, y_train)\n",
    "    accuracy_train.append(bdt.score(X_train, y_train))\n",
    "    accuracy_test.append(bdt.score(X_test, y_test))\n",
    "\n",
    "\n",
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance des features selectionnées par AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure()\n",
    "    plt.barh(range(n_features),sorted(model.feature_importances_), align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns) \n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(\"Features importance\", fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importances(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Classification multiclasse\n",
    "\n",
    "## 1. Création de ymulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On repart du dataset initial afin d'attribuer les 3 nouvelles modalités à partir de quality\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :11]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur l'application de la valeur des modalités : \n",
    "\n",
    "- Inférieur à 5 : 0\n",
    "- Egale à 5 : 1\n",
    "- Supérieur à 5 : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implémentation de ymulti en fonction de la moyenne\n",
    "\n",
    "ymulti = []\n",
    "\n",
    "for i in y:\n",
    "    \n",
    "    if i < 5:\n",
    "        ymulti.append(0)\n",
    "        \n",
    "    elif i == 5:\n",
    "        ymulti.append(1)\n",
    "    else:\n",
    "        ymulti.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ymulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1=df.assign(ymulti= ymulti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>ymulti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  ymulti  \n",
       "0         9.4        5       1  \n",
       "1         9.8        5       1  \n",
       "2         9.8        5       1  \n",
       "3         9.8        6       2  \n",
       "4         9.4        5       1  \n",
       "...       ...      ...     ...  \n",
       "1594     10.5        5       1  \n",
       "1595     11.2        6       2  \n",
       "1596     11.0        6       2  \n",
       "1597     10.2        5       1  \n",
       "1598     11.0        6       2  \n",
       "\n",
       "[1599 rows x 13 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>ymulti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  ymulti  \n",
       "0         9.4       1  \n",
       "1         9.8       1  \n",
       "2         9.8       1  \n",
       "3         9.8       2  \n",
       "4         9.4       1  \n",
       "...       ...     ...  \n",
       "1594     10.5       1  \n",
       "1595     11.2       2  \n",
       "1596     11.0       2  \n",
       "1597     10.2       1  \n",
       "1598     11.0       2  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On cherche à prédire ymulti, on supprime quality\n",
    "new_df1.drop(\"quality\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df1.iloc[:, :11]\n",
    "y = new_df1.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre d'occurence par modalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    855\n",
       "1    681\n",
       "0     63\n",
       "Name: ymulti, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df1['ymulti'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    588\n",
       "1    486\n",
       "0     45\n",
       "Name: ymulti, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 588, 1: 588, 0: 588})\n"
     ]
    }
   ],
   "source": [
    "# Oversample and plot imbalanced dataset with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# transform the dataset\n",
    "oversample = SMOTE(random_state=0, sampling_strategy='all')\n",
    "X_train_balanced, y_train_balanced = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train_balanced)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train_balanced, y_train_balanced, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_val1, y_train2, y_val1 = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultats sur la base avec les données équilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3452830188679245"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=1, early_stopping = True, max_iter=300,learning_rate_init=0.1)\n",
    "clf.fit(X_train1, y_train1)\n",
    "\n",
    "clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'activation' : ['identity','logistic', 'tahn', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "              'learning_rate' : ['constant', 'invscaling', 'adaptive']\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gride = GridSearchCV(clf, param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.57941477 0.35816135 0.42383398 0.56076824 0.36707152 0.4813831\n",
      " 0.54054179 0.40115204 0.44571278 0.38003028 0.34844475 0.37041901\n",
      " 0.50245877 0.35897765 0.38415128 0.37436227 0.40518416 0.4133307\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.33954445 0.33467957 0.32982456\n",
      " 0.43752016 0.36545209 0.33387314 0.33954445 0.3371153  0.33306672]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=MLPClassifier(early_stopping=True, hidden_layer_sizes=1,\n",
       "                                     learning_rate_init=0.1, max_iter=300),\n",
       "             param_grid={'activation': ['identity', 'logistic', 'tahn', 'relu'],\n",
       "                         'learning_rate': ['constant', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'solver': ['lbfgs', 'sgd', 'adam']})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gride.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', early_stopping=True, hidden_layer_sizes=1,\n",
       "              learning_rate_init=0.1, max_iter=300, solver='lbfgs')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gride.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  gride.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', early_stopping=True, hidden_layer_sizes=1,\n",
       "              learning_rate_init=0.1, max_iter=300, solver='lbfgs')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41132075471698115"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 2, 0, 1, 0, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 0,\n",
       "       0, 2, 1, 1, 2, 0, 1, 2, 0, 1, 1, 2, 2, 0, 1, 1, 2, 1, 1, 0, 2, 0,\n",
       "       2, 1, 1, 2, 2, 2, 2, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       2, 1, 2, 0, 0, 1, 1, 2, 2, 0, 1, 0, 0, 1, 0, 0, 2, 2, 1, 1, 2, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 2, 2, 2, 0, 1, 1, 2, 1, 0, 0, 2, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 2, 0, 1, 1, 0, 1, 0, 2, 0, 0, 2, 1, 2, 2, 0, 2,\n",
       "       0, 2, 2, 1, 1, 0, 1, 2, 2, 2, 2, 0, 0, 2, 2, 0, 1, 0, 2, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 2, 2, 1, 0, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2,\n",
       "       2, 0, 0, 2, 1, 0, 1, 1, 1, 1, 0, 2, 1, 0, 2, 1, 0, 0, 1, 0, 2, 0,\n",
       "       2, 1, 2, 0, 1, 1, 0, 1, 0, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2,\n",
       "       2, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 2, 1, 0, 1, 0, 2, 1, 2, 2, 0, 2, 0, 0, 0, 0, 0, 1, 2,\n",
       "       2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 1, 1, 2, 1,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 2, 1, 2, 1, 0, 1, 2, 1,\n",
       "       1, 1, 2, 1, 2, 2, 1, 0, 1, 2, 0, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       2, 1, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 1, 0, 2, 2, 0, 0, 2, 1,\n",
       "       0, 2, 2, 1, 2, 0, 2, 2, 1, 0, 1, 0, 1, 1, 1, 2, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 0, 2, 0, 0,\n",
       "       0, 1, 2, 1, 1, 0, 1, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0,\n",
       "       0, 0, 2, 1, 2, 0, 2, 1, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0, 0, 2, 0,\n",
       "       1, 0], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99, 41, 38],\n",
       "       [70, 73, 40],\n",
       "       [84, 39, 46]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultats sur la base avec les données non-équilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5327380952380952"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=1, early_stopping = True, max_iter=300,learning_rate_init=0.1)\n",
    "clf.fit(X_train2, y_train2)\n",
    "\n",
    "clf.score(X_val1, y_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.65783929 0.50311939 0.56565409 0.67940552 0.5633758  0.60155969\n",
      " 0.70102891 0.52996897 0.61563776 0.60157602 0.57092928 0.52235016\n",
      " 0.59542708 0.53508901 0.50566716 0.55440144 0.52235016 0.50324187\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.56821003 0.50324187 0.50568349\n",
      " 0.54018455 0.50311939 0.5529234  0.58876368 0.52235016 0.52235016]\n",
      "  category=UserWarning\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', early_stopping=True, hidden_layer_sizes=1,\n",
       "              learning_rate='adaptive', learning_rate_init=0.1, max_iter=300,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {'activation' : ['identity','logistic', 'tahn', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "              'learning_rate' : ['constant', 'invscaling', 'adaptive']\n",
    "             }\n",
    "\n",
    "gride = GridSearchCV(clf, param_grid, cv = 5)\n",
    "\n",
    "gride.fit(X_train2, y_train2)\n",
    "\n",
    "model =  gride.best_estimator_\n",
    "model.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6458333333333334"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_val1, y_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model.predict(X_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   3,   5],\n",
       "       [  0,  61,  88],\n",
       "       [  0,  23, 156]], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    179\n",
       "1    149\n",
       "0      8\n",
       "Name: ymulti, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
