{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de données\n",
    "\n",
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('beer_quality.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "4     53\n",
       "8     18\n",
       "3     10\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données en features et label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  \n",
       "0         9.4  \n",
       "1         9.8  \n",
       "2         9.8  \n",
       "3         9.8  \n",
       "4         9.4  \n",
       "...       ...  \n",
       "1594     10.5  \n",
       "1595     11.2  \n",
       "1596     11.0  \n",
       "1597     10.2  \n",
       "1598     11.0  \n",
       "\n",
       "[1599 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       5\n",
       "2       5\n",
       "3       6\n",
       "4       5\n",
       "       ..\n",
       "1594    5\n",
       "1595    6\n",
       "1596    6\n",
       "1597    5\n",
       "1598    6\n",
       "Name: quality, Length: 1599, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données en train et en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Classification Binaire \n",
    "\n",
    "## Création de nouvelle variable en fonction de la médiane de y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "#Calcul de la médiane\n",
    "statistics.median(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implémentation de ybin en fonction de la médiane \n",
    "\n",
    "ybin = []\n",
    "\n",
    "for i in y:\n",
    "    m = 6\n",
    "    if i < m:\n",
    "        ybin.append(0)\n",
    "        \n",
    "    else:\n",
    "        ybin.append(1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df.assign(ybin= ybin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>ybin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  ybin  \n",
       "0         9.4        5     0  \n",
       "1         9.8        5     0  \n",
       "2         9.8        5     0  \n",
       "3         9.8        6     1  \n",
       "4         9.4        5     0  \n",
       "...       ...      ...   ...  \n",
       "1594     10.5        5     0  \n",
       "1595     11.2        6     1  \n",
       "1596     11.0        6     1  \n",
       "1597     10.2        5     0  \n",
       "1598     11.0        6     1  \n",
       "\n",
       "[1599 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>ybin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  ybin  \n",
       "0         9.4     0  \n",
       "1         9.8     0  \n",
       "2         9.8     0  \n",
       "3         9.8     1  \n",
       "4         9.4     0  \n",
       "...       ...   ...  \n",
       "1594     10.5     0  \n",
       "1595     11.2     1  \n",
       "1596     11.0     1  \n",
       "1597     10.2     0  \n",
       "1598     11.0     1  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On cherche à prédire ybin, on supprime quality\n",
    "new_df.drop(\"quality\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.iloc[:, :11]\n",
    "y = new_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc=StandardScaler()\n",
    "\n",
    "#scaler = sc.fit(X)\n",
    "#X = scaler.transform(X)\n",
    "\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth' : np.arange(1,5),\n",
    "             'min_samples_split' : np.arange (1,5)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(clf, param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [       nan 0.68003684 0.68003684 0.68003684        nan 0.68004885\n",
      " 0.68004885 0.68004885        nan 0.68095372 0.68095372 0.68095372\n",
      "        nan 0.71487028 0.71487028 0.71397341]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(criterion='entropy'),\n",
       "             param_grid={'max_depth': array([1, 2, 3, 4]),\n",
       "                         'min_samples_split': array([1, 2, 3, 4])})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 1\n",
    "model_a = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1), n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   n_estimators=100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7083333333333334"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import pylab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = [10,20, 30, 40, 50, 60,70,80,90,100]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=n_estimators[i])\n",
    "\n",
    "    # Train Adaboost Classifer\n",
    "    model = bdt.fit(X_train, y_train)\n",
    "    accuracy_train.append(bdt.score(X_train, y_train))\n",
    "    accuracy_test.append(bdt.score(X_test, y_test))\n",
    "\n",
    "\n",
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = [10,20, 30, 40, 50, 60,70,80,90,100]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5), algorithm=\"SAMME\", n_estimators=n_estimators[i])\n",
    "\n",
    "    # Train Adaboost Classifer\n",
    "    model = bdt.fit(X_train, y_train)\n",
    "    accuracy_train.append(bdt.score(X_train, y_train))\n",
    "    accuracy_test.append(bdt.score(X_test, y_test))\n",
    "\n",
    "\n",
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance des features selectionnées par AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure()\n",
    "    plt.barh(range(n_features),sorted(model.feature_importances_), align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns) \n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(\"Features importance\", fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importances(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Classification multiclasse\n",
    "\n",
    "## 1. Création de ymulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On repart du dataset initial afin d'attribuer les 3 nouvelles modalités à partir de quality\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :11]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur l'application de la valeur des modalités : \n",
    "\n",
    "- Inférieur à 5 : 0\n",
    "- Egale à 5 : 1\n",
    "- Supérieur à 5 : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implémentation de ymulti en fonction de la moyenne\n",
    "\n",
    "ymulti = []\n",
    "\n",
    "for i in y:\n",
    "    \n",
    "    if i < 5:\n",
    "        ymulti.append(0)\n",
    "        \n",
    "    elif i == 5:\n",
    "        ymulti.append(1)\n",
    "    else:\n",
    "        ymulti.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ymulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1=df.assign(ymulti= ymulti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>ymulti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  ymulti  \n",
       "0         9.4        5       1  \n",
       "1         9.8        5       1  \n",
       "2         9.8        5       1  \n",
       "3         9.8        6       2  \n",
       "4         9.4        5       1  \n",
       "...       ...      ...     ...  \n",
       "1594     10.5        5       1  \n",
       "1595     11.2        6       2  \n",
       "1596     11.0        6       2  \n",
       "1597     10.2        5       1  \n",
       "1598     11.0        6       2  \n",
       "\n",
       "[1599 rows x 13 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>ymulti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  ymulti  \n",
       "0         9.4       1  \n",
       "1         9.8       1  \n",
       "2         9.8       1  \n",
       "3         9.8       2  \n",
       "4         9.4       1  \n",
       "...       ...     ...  \n",
       "1594     10.5       1  \n",
       "1595     11.2       2  \n",
       "1596     11.0       2  \n",
       "1597     10.2       1  \n",
       "1598     11.0       2  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On cherche à prédire ymulti, on supprime quality\n",
    "new_df1.drop(\"quality\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df1.iloc[:, :11]\n",
    "y = new_df1.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre d'occurence par modalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    855\n",
       "1    681\n",
       "0     63\n",
       "Name: ymulti, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df1['ymulti'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    588\n",
       "1    486\n",
       "0     45\n",
       "Name: ymulti, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 588, 1: 588, 0: 588})\n"
     ]
    }
   ],
   "source": [
    "# Oversample and plot imbalanced dataset with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# transform the dataset\n",
    "oversample = SMOTE(random_state=0, sampling_strategy='all')\n",
    "X_train_balanced, y_train_balanced = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train_balanced)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train_balanced, y_train_balanced, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_val1, y_train2, y_val1 = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultats sur la base avec les données équilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3452830188679245"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=1, early_stopping = True)\n",
    "clf.fit(X_train1, y_train1)\n",
    "\n",
    "clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'hidden_layer_sizes' : np.arange(1,11)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "gride = GridSearchCV(clf, param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=MLPClassifier(early_stopping=True, hidden_layer_sizes=1),\n",
       "             param_grid={'hidden_layer_sizes': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])})"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gride.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=6)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gride.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  gride.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=6)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.330188679245283"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2], dtype=int64)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0, 178],\n",
       "       [  0,   0, 183],\n",
       "       [  0,   0, 169]], dtype=int64)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultats sur la base avec les données non-équilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44345238095238093"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=1, early_stopping = True)\n",
    "clf.fit(X_train2, y_train2)\n",
    "\n",
    "clf.score(X_val1, y_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=6)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'hidden_layer_sizes' : np.arange(1,11)}\n",
    "gride = GridSearchCV(clf, param_grid, cv = 5)\n",
    "\n",
    "gride.fit(X_train2, y_train2)\n",
    "\n",
    "model =  gride.best_estimator_\n",
    "model.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5327380952380952"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_val1, y_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model.predict(X_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   8],\n",
       "       [  0,   0, 149],\n",
       "       [  0,   0, 179]], dtype=int64)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    183\n",
       "0    178\n",
       "2    169\n",
       "Name: ymulti, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
