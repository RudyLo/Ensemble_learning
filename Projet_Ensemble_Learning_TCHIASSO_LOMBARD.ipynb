{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de données\n",
    "\n",
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('beer_quality.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "4     53\n",
       "8     18\n",
       "3     10\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données en features et label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  \n",
       "0         9.4  \n",
       "1         9.8  \n",
       "2         9.8  \n",
       "3         9.8  \n",
       "4         9.4  \n",
       "...       ...  \n",
       "1594     10.5  \n",
       "1595     11.2  \n",
       "1596     11.0  \n",
       "1597     10.2  \n",
       "1598     11.0  \n",
       "\n",
       "[1599 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       5\n",
       "2       5\n",
       "3       6\n",
       "4       5\n",
       "       ..\n",
       "1594    5\n",
       "1595    6\n",
       "1596    6\n",
       "1597    5\n",
       "1598    6\n",
       "Name: quality, Length: 1599, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données en train et en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Classification Binaire \n",
    "\n",
    "## Création de nouvelle variable en fonction de la médiane de y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "#Calcul de la médiane\n",
    "statistics.median(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implémentation de ybin en fonction de la médiane \n",
    "\n",
    "ybin = []\n",
    "\n",
    "for i in y:\n",
    "    m = 6\n",
    "    if i < m:\n",
    "        ybin.append(0)\n",
    "        \n",
    "    else:\n",
    "        ybin.append(1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df.assign(ybin= ybin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>ybin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  ybin  \n",
       "0         9.4        5     0  \n",
       "1         9.8        5     0  \n",
       "2         9.8        5     0  \n",
       "3         9.8        6     1  \n",
       "4         9.4        5     0  \n",
       "...       ...      ...   ...  \n",
       "1594     10.5        5     0  \n",
       "1595     11.2        6     1  \n",
       "1596     11.0        6     1  \n",
       "1597     10.2        5     0  \n",
       "1598     11.0        6     1  \n",
       "\n",
       "[1599 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>ybin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  ybin  \n",
       "0         9.4     0  \n",
       "1         9.8     0  \n",
       "2         9.8     0  \n",
       "3         9.8     1  \n",
       "4         9.4     0  \n",
       "...       ...   ...  \n",
       "1594     10.5     0  \n",
       "1595     11.2     1  \n",
       "1596     11.0     1  \n",
       "1597     10.2     0  \n",
       "1598     11.0     1  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On cherche à prédire ybin, on supprime quality\n",
    "new_df.drop(\"quality\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.iloc[:, :11]\n",
    "y = new_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc=StandardScaler()\n",
    "\n",
    "#scaler = sc.fit(X)\n",
    "#X = scaler.transform(X)\n",
    "\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth' : np.arange(1,5),\n",
    "             'min_samples_split' : np.arange (1,5)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(clf, param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [       nan 0.67654949 0.67654949 0.67654949        nan 0.67654949\n",
      " 0.67654949 0.67654949        nan 0.6676009  0.6676009  0.6676009\n",
      "        nan 0.66939462 0.6676049  0.6676049 ]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(criterion='entropy'),\n",
       "             param_grid={'max_depth': array([1, 2, 3, 4]),\n",
       "                         'min_samples_split': array([1, 2, 3, 4])})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.0019948482513427734s\n"
     ]
    }
   ],
   "source": [
    "model = grid.best_estimator_\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6375"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 1\n",
    "model_a = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1), n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.1705455780029297s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model_a.fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70625"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import pylab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = [10,20, 30, 40, 50, 60,70,80,90,100]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=n_estimators[i])\n",
    "\n",
    "    # Train Adaboost Classifer\n",
    "    model = bdt.fit(X_train, y_train)\n",
    "    accuracy_train.append(bdt.score(X_train, y_train))\n",
    "    accuracy_test.append(bdt.score(X_test, y_test))\n",
    "\n",
    "\n",
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = [10,20, 30, 40, 50, 60,70,80,90,100]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5), algorithm=\"SAMME\", n_estimators=n_estimators[i])\n",
    "\n",
    "    # Train Adaboost Classifer\n",
    "    model = bdt.fit(X_train, y_train)\n",
    "    accuracy_train.append(bdt.score(X_train, y_train))\n",
    "    accuracy_test.append(bdt.score(X_test, y_test))\n",
    "\n",
    "\n",
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance des features selectionnées par AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure()\n",
    "    plt.barh(range(n_features),sorted(model.feature_importances_), align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns) \n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(\"Features importance\", fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importances(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Classification multiclasse\n",
    "\n",
    "## 1. Création de ymulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On repart du dataset initial afin d'attribuer les 3 nouvelles modalités à partir de quality\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :11]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur l'application de la valeur des modalités : \n",
    "\n",
    "- Inférieur à 5 : 0\n",
    "- Egale à 5 : 1\n",
    "- Supérieur à 5 : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implémentation de ymulti en fonction de la moyenne\n",
    "\n",
    "ymulti = []\n",
    "\n",
    "for i in y:\n",
    "    \n",
    "    if i < 5:\n",
    "        ymulti.append(0)\n",
    "        \n",
    "    elif i == 5:\n",
    "        ymulti.append(1)\n",
    "    else:\n",
    "        ymulti.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ymulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1=df.assign(ymulti= ymulti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>ymulti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  ymulti  \n",
       "0         9.4        5       1  \n",
       "1         9.8        5       1  \n",
       "2         9.8        5       1  \n",
       "3         9.8        6       2  \n",
       "4         9.4        5       1  \n",
       "...       ...      ...     ...  \n",
       "1594     10.5        5       1  \n",
       "1595     11.2        6       2  \n",
       "1596     11.0        6       2  \n",
       "1597     10.2        5       1  \n",
       "1598     11.0        6       2  \n",
       "\n",
       "[1599 rows x 13 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>ymulti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  ymulti  \n",
       "0         9.4       1  \n",
       "1         9.8       1  \n",
       "2         9.8       1  \n",
       "3         9.8       2  \n",
       "4         9.4       1  \n",
       "...       ...     ...  \n",
       "1594     10.5       1  \n",
       "1595     11.2       2  \n",
       "1596     11.0       2  \n",
       "1597     10.2       1  \n",
       "1598     11.0       2  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On cherche à prédire ymulti, on supprime quality\n",
    "new_df1.drop(\"quality\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df1.iloc[:, :11]\n",
    "y = new_df1.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre d'occurence par modalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    855\n",
       "1    681\n",
       "0     63\n",
       "Name: ymulti, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df1['ymulti'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    588\n",
       "1    486\n",
       "0     45\n",
       "Name: ymulti, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 588, 1: 588, 0: 588})\n"
     ]
    }
   ],
   "source": [
    "# Oversample and plot imbalanced dataset with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# transform the dataset\n",
    "oversample = SMOTE(random_state=0, sampling_strategy='all')\n",
    "X_train_balanced, y_train_balanced = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train_balanced)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train_balanced, y_train_balanced, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_val1, y_train2, y_val1 = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultats sur la base avec les données équilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.029286861419677734s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33584905660377357"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=1, early_stopping = True, max_iter=300,learning_rate_init=0.1)\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(X_train1, y_train1)\n",
    "stop = time.time()\n",
    "\n",
    "clf.score(X_val, y_val)\n",
    "\n",
    "\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'activation' : ['identity','logistic', 'tahn', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "              'learning_rate' : ['constant', 'invscaling', 'adaptive']\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gride = GridSearchCV(clf, param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.53231296 0.33954445 0.43687173 0.55342813 0.37436227 0.44810572\n",
      " 0.47900332 0.41814292 0.46924723 0.4935486  0.36545538 0.37760113\n",
      " 0.33954445 0.33549258 0.40690234 0.39217603 0.35492907 0.38731444\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.33954445 0.35735822 0.35735822\n",
      " 0.33954445 0.33387314 0.33549587 0.35498502 0.33387314 0.33306672]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=MLPClassifier(early_stopping=True, hidden_layer_sizes=1,\n",
       "                                     learning_rate_init=0.1, max_iter=300),\n",
       "             param_grid={'activation': ['identity', 'logistic', 'tahn', 'relu'],\n",
       "                         'learning_rate': ['constant', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'solver': ['lbfgs', 'sgd', 'adam']})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gride.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', early_stopping=True, hidden_layer_sizes=1,\n",
       "              learning_rate='invscaling', learning_rate_init=0.1, max_iter=300,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gride.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  gride.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.0034685134887695312s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "model.fit(X_train1, y_train1)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41132075471698115"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 1, 1, 2, 1, 1, 1, 1, 2, 0, 0, 0,\n",
       "       0, 2, 1, 1, 2, 0, 1, 2, 0, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 2, 2, 0,\n",
       "       2, 1, 1, 2, 2, 2, 2, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 2,\n",
       "       2, 1, 0, 0, 0, 1, 1, 2, 2, 0, 1, 0, 0, 2, 0, 0, 0, 2, 2, 1, 1, 0,\n",
       "       1, 2, 1, 0, 1, 1, 0, 2, 2, 2, 2, 0, 1, 1, 2, 1, 0, 0, 2, 0, 0, 0,\n",
       "       2, 1, 1, 0, 1, 0, 2, 2, 1, 1, 0, 1, 0, 2, 0, 2, 2, 1, 2, 2, 0, 2,\n",
       "       0, 2, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 0, 1, 2, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 2, 0, 2, 0, 1, 0, 0, 2, 2, 0, 2, 0, 1, 0, 2, 0, 2,\n",
       "       2, 0, 2, 2, 1, 0, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 0, 0, 1, 0, 2, 0,\n",
       "       2, 1, 2, 2, 1, 1, 0, 1, 0, 2, 1, 2, 0, 0, 1, 2, 0, 0, 0, 2, 0, 0,\n",
       "       2, 0, 0, 2, 0, 0, 2, 2, 0, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 0,\n",
       "       1, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 2, 1, 0, 1, 0, 2, 1, 2, 2, 0, 2, 0, 0, 0, 0, 0, 1, 2,\n",
       "       2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 1, 2, 0, 2, 2, 2, 1, 1, 1, 2, 1,\n",
       "       0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 2, 1, 2, 1, 2, 1, 2, 1,\n",
       "       1, 1, 2, 1, 2, 2, 1, 0, 1, 2, 0, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 1, 0,\n",
       "       2, 1, 2, 1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 2, 0, 1, 1,\n",
       "       0, 2, 1, 1, 1, 0, 2, 2, 1, 0, 1, 0, 1, 1, 1, 2, 0, 1, 1, 2, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 2, 1, 1, 0, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0,\n",
       "       0, 0, 2, 1, 1, 2, 2, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 2, 0, 2, 2, 1, 0, 0, 1, 2, 2, 2, 1, 0, 2, 0, 0, 2, 0,\n",
       "       1, 0], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[93, 43, 42],\n",
       "       [52, 72, 59],\n",
       "       [74, 42, 53]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultats sur la base avec les données non-équilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.023814678192138672s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5327380952380952"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=1, early_stopping = True, max_iter=300,learning_rate_init=0.1)\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(X_train2, y_train2)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "clf.score(X_val1, y_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.6781153  0.52235016 0.59517393 0.68708966 0.52235016 0.58882901\n",
      " 0.66525396 0.5784991  0.59901192 0.60172301 0.50696554 0.5274457\n",
      " 0.6041238  0.48528499 0.52235016 0.52235016 0.52871958 0.52631063\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.52235016 0.48401111 0.48528499\n",
      " 0.52235016 0.50311939 0.50696554 0.60155153 0.52235016 0.50311939]\n",
      "  category=UserWarning\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.12266969680786133s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {'activation' : ['identity','logistic', 'tahn', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "              'learning_rate' : ['constant', 'invscaling', 'adaptive']\n",
    "             }\n",
    "\n",
    "gride = GridSearchCV(clf, param_grid, cv = 5)\n",
    "\n",
    "gride.fit(X_train2, y_train2)\n",
    "\n",
    "model =  gride.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.06036829948425293s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(X_train2, y_train2)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7261904761904762"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_val1, y_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model.predict(X_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   5,   3],\n",
       "       [  0, 100,  49],\n",
       "       [  0,  35, 144]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    179\n",
       "1    149\n",
       "0      8\n",
       "Name: ymulti, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "### Données équilibrées "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "n_estimators = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    bagging = BaggingClassifier(base_estimator=MLPClassifier(early_stopping=True, hidden_layer_sizes=1))\n",
    "    model = bagging.fit(X_train1, y_train1)\n",
    "    accuracy_train.append(bagging.score(X_train1, y_train1))\n",
    "    accuracy_test.append(bagging.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données non-équilibrées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "n_estimators = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    bagging = BaggingClassifier(base_estimator=MLPClassifier(hidden_layer_sizes=1, early_stopping = True, max_iter=300,learning_rate_init=0.1))\n",
    "    model = bagging.fit(X_train2, y_train2)\n",
    "    accuracy_train.append(bagging.score(X_train1, y_train1))\n",
    "    accuracy_test.append(bagging.score(X_val1, y_val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 \n",
    "\n",
    "## Entrainement de forêt aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"max_depth\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "    \"n_estimators\": [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(clf, param_dist) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données équilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20],\n",
       "                                        'n_estimators': [25, 50, 75, 100, 125,\n",
       "                                                         150, 175, 200, 225,\n",
       "                                                         250, 275, 300]})"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, n_estimators=75)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.18396592140197754s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8018867924528302"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train1, y_train1)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "model.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    model1 = model.fit(X_train1, y_train1)\n",
    "    accuracy_train.append(model.score(X_train1, y_train1))\n",
    "    accuracy_test.append(model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model1.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[170,   7,   1],\n",
       "       [  7, 134,  42],\n",
       "       [  5,  35, 129]], dtype=int64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importances(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données non-équilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20],\n",
       "                                        'n_estimators': [25, 50, 75, 100, 125,\n",
       "                                                         150, 175, 200, 225,\n",
       "                                                         250, 275, 300]})"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=12, n_estimators=250)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.42688441276550293s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7946428571428571"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = search.best_estimator_\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train2, y_train2)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "model.score(X_val1,y_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    model2 = model.fit(X_train2, y_train2)\n",
    "    accuracy_train.append(model.score(X_train2, y_train2))\n",
    "    accuracy_test.append(model.score(X_val1, y_val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAdXklEQVR4nO3df3RU5b3v8feXkBD5TSAoEjXx1NPKj4AYkdPeq1gUAeFgxbWK1/aKy1u1/ijqcXXZSq8Vi9qzvG1Xl7YuPBdttfci1arIqT+QC3qOVSQoIIgo8kMiVCK/0QAJee4fzx5mSCbJTkgymSef11p7zcyz98x+nmzms5/97D0bc84hIiLh6pLpCoiISNtS0IuIBE5BLyISOAW9iEjgFPQiIoHrmukK1DVgwABXXFyc6WqIiGSVlStXfuGcK0w3r8MFfXFxMeXl5ZmuhohIVjGzrQ3N09CNiEjgFPQiIoFT0IuIBK7DjdGnU11dTUVFBYcOHcp0VbJWfn4+RUVF5ObmZroqItLOsiLoKyoq6NWrF8XFxZhZpquTdZxz7Nq1i4qKCkpKSjJdHRFpZ1kxdHPo0CH69++vkG8hM6N///46IhLppLIi6AGF/AnS30+k88qKoZs4amth+3bIzYWuXZOPialL1uzS4OhRqKnxU3V18tEMunWDvDz/2DWYrScibSmYqKipgc8/h4Zur58a+ul2BqllOTk+VFtLbW394K4b4qmPtbXxPjcnJxn6qTuAxPOcnNZrg4hkr2CCPi8PRo1K9obrhmfq86qqZFlD6u4M0u0UcnKaXld1ta9TOmbwxBP388Mf/pSuXX1AN7Ze5+DIETh8GG655X9w7bV3cMYZQzh0CPbvr7+DSHxmYgdw4AC8+iqUlMDpp/syCUt1NWzbFr+z0Bq6doUePfx00kmt20nKhCNH4Msv/VRTAwMG+LZlc7uso/0PU2VlZa7uLRDWr1/P2Wef3errci5eUCce43x54h41JHYUvXr15ODBg2nq5nDO0SXmmFOiLYcPJ3cGqc+PHIHKyvVMnOj/jmYweDAUF/vgT52Ki6GoSEcEHZ1zsHUrvPMOLF/up3ff9R2ZTDGD7t2Twd/YFHe51Cknx7e7qioZxg1NX33V9DLppnQdwJNOgoEDk1Nh4fGv687Ly8vE395WOufK0s3Luh79bbfBqlWt+5kjR8JvftP0clOnXs62bduoqjrEjTfO5Pvfv55ly15m9uyfUlt7lMLCASxZsoSDBw9y6623Ul5ejplxzz33MG3atHqfd9ddd1FVVcXIkSMZOnQoc+bMYeLEiVx00UW89dZbPP/88zz44IOsWLGCqqoqrrzySu69914Axo4dy0MPPURZWRk9e/Zk5syZLFq0iJNOOokXXniBQYNOPm5dzsHatfD667B5s5+2bPGPy5bBU08dP+yVkwO9ezf/ixhnysvL7t5RpuzdCytWHB/sO3f6ed26+SPaG26A0lLfmWgv1dXxAnT37nih2pi8PL++5vRPG9v5FBQ0vWPZtcv/nXfuhMpK+PvfYc0aP1R85Ej6dfbt2/jOIHWnUFDQ9p2qrAv6THr88XkUFBRQVVXFeeedx/TpU5k58we88cYblJSUsHv3bgDuu+8++vTpw/vvvw/Anj170n7egw8+yMMPP8yqaM+1ZcsWNmzYwOOPP87vfvc7AObMmUNBQQFHjx5l3LhxrFmzhtLS0uM+58svv2TMmDHMmTOHH//4xzz22GPMmjXruGXM/FHEBRf4qa4jR+DTT5M7gC1bYN+++l/ML77wvcjUHlNze5A5OfW/UO19yN+rV/2jmJISf5jeEXZC1dU+TJYvTwb7hx8m53/jGzBxIoweDeef3/7h3loSwyRxe99ffeXDvjlHDG31b8s5Pxya2AmkTpWVyecffwxvvum/O+lGBbp08f/uBg702/Lf/q3165p1QR+n591Wfvvb3/Lcc88BsG3bNubOncsFF1xw7EdIBQUFALz22mvMnz//2Pv69esXex1nnHEGY8aMOfZ6wYIFzJ07l5qaGnbs2MEHH3xQL+jz8vKYPHkyAOeeey6LFy9udtvy8uBrX/NTc9XWtvwwOTG153CDc753uXKl762l6tmz/nBW6uvevdumPlu2JHvpy5fDe+9B4mcPiQD43vd8sJ93nu8xhiAvz0/N+Ip0GGb+30Pv3vG+N0eP+n936XYGialHj7apa9YFfaYsW7aM1157jbfeeovu3bszduxYRowYwYYNG+ot65xr8XXrPVK29ObNm3nooYdYsWIF/fr1Y8aMGWl/9JSbm3tsfTk5OdQ093j4BHXp4gOyZ892XW2r2L8/OYSVOpy1eTMsXQp1T58UFDS8Eyguhvz8pte5Z48fgkmE+jvv+C89+Pefey7cdJMP9/PP9yfOO8JRhpyYnBw/VFNYCEOHtu+6FfQx7du3j379+tG9e3c+/PBD3n77bQ4fPszrr7/O5s2bjw3dFBQUMH78eB5++GF+Ex1+7Nmzp8FefW5uLtXV1WnvQbN//3569OhBnz59+Pzzz3nppZcYO3ZsWzaz0+nd2w971DlIAnxPe9eu+juAzZv9sMrChfXHaAcNqr8TKCqCjRuTwf7RR35ZMzj7bLjssmSoDxuWnUMw0rEp6GOaMGECjz76KKWlpXz9619nzJgxFBYWMnfuXK644gpqa2sZOHAgixcvZtasWdx8880MGzaMnJwc7rnnHq644oq0n3v99ddTWlrKqFGjmDNnznHzRowYwTnnnMPQoUM588wz+da3vtUeTZWImR87HTDAD5fUVVvrT8yl7gAS05tvwvz5x19ae8opPsxnzPBDMGVl0KdPuzVHOrFOfXllZ6O/Y/uqroaKCn9de3ExnHaahmCk7QR1eaVItsjNTQ7jiGSSgr6dnH/++Rw+fPi4sieffJLhw4dnqEYi0lko6NvJ8uXLM10FEemksuiejiIi0hIKehGRwCnoRUQCp6DPsPvvv7/F733iiSfYvn17K9ZGREKkoM8wBb2ItDUFfTNcfvnlnHvuuQwdOpS5c+cC8PLLLzNq1ChGjBjBuHHjADh48CDXXnstw4cPp7S0lGeffTbt56Xepvjqq68G4KmnnmL06NGMHDmSG264gaNHj3L06FFmzJjBsGHDGD58OL/+9a955plnKC8v5+qrr2bkyJFUZfIm5CLSoWXf5ZUZvCH9vHnH36Z46tSp/OAHrXeb4vXr1/P000/z5ptvkpuby0033cSf/vQnhg4dymeffcbatWsB2Lt3L3379uXhhx8+dk96EZGGZF/QZ1Bb36Z4yZIlrFy5kvOiG6tUVVUxcOBApkyZwqZNm7j11lu57LLLGD9+fGs2S0QCl31Bn6Eb0rfHbYqdc1xzzTU88MAD9eatXr2aV155hUceeYQFCxYwb968FrVDRDofjdHH1NRtioFjQzeJ2xQnNDR0A8nbFAOMGzeOZ555hp3R/w+3e/dutm7dyhdffEFtbS3Tpk3jvvvu49133wWgV69eHDhwoE3aKyLhUNDHNGHCBGpqaigtLeVnP/tZvdsUjxgxgu9+97sAzJo1iz179jBs2DBGjBjB0qVLG/zcxG2Kr776aoYMGcIvfvELxo8fT2lpKZdccgk7duzgs88+Y+zYsYwcOZIZM2Yc6/HPmDGDG2+8USdjRaRRuk1xJ6K/o0i4GrtNsXr0IiKBy76TsVlKtykWkUxR0LcT3aZYRDIla4ZuOtq5hGyjv59I55UVQZ+fn8+uXbsUVi3knGPXrl3k5+dnuioikgFZMXRTVFRERUUFlZWVma5K1srPz6eoqCjT1RCRDMiKoM/NzT12mwEREWmeWEM3ZjbBzDaY2UYzuyvN/DPMbImZrTGzZWZWlDLvqJmtiqaFrVl5ERFpWpM9ejPLAR4BLgEqgBVmttA590HKYg8Bf3TO/cHMvg08AHw/mlflnBvZyvUWEZGY4vToRwMbnXObnHNHgPnA1DrLDAGWRM+XppkvIiIZEifoBwPbUl5XRGWpVgPTouffAXqZWf/odb6ZlZvZ22Z2eboVmNn10TLlOuEqItK64gR9uvvt1r3O8U7gQjN7D7gQ+AyoieadHt1/4b8BvzGzf6j3Yc7Ndc6VOefKCgsL49deRESaFOeqmwrgtJTXRcBx/1Gpc247cAWAmfUEpjnn9qXMwzm3ycyWAecAn5xwzUVEJJY4PfoVwFlmVmJmecB04LirZ8xsgJklPusnwLyovJ+ZdUssA3wLSD2JKyIibazJoHfO1QC3AK8A64EFzrl1ZjbbzP45WmwssMHMPgJOBuZE5WcD5Wa2Gn+S9sE6V+uIiEgby4r70YuISON0P3oRkU5MQS8iEjgFvYhI4BT0IiKBU9CLiAROQS8iEjgFvYhI4BT0IiKBU9CLiAROQS8iEjgFvYhI4BT0IiKBU9CLiAROQS8iEjgFvYhI4BT0IiKBU9CLiAROQS8iEjgFvYhI4BT0IiKBU9CLiAROQS8iEjgFvYhI4BT0IiKBU9CLiAROQS8iEjgFvYhI4BT0IiKBU9CLiAROQS8iEjgFvYhI4BT0IiKBU9CLiAROQS8iEjgFvYhI4BT0IiKBU9CLiAQuVtCb2QQz22BmG83srjTzzzCzJWa2xsyWmVlRyrxrzOzjaLqmNSsvIiJNazLozSwHeASYCAwBrjKzIXUWewj4o3OuFJgNPBC9twC4BzgfGA3cY2b9Wq/6IiLSlDg9+tHARufcJufcEWA+MLXOMkOAJdHzpSnzLwUWO+d2O+f2AIuBCSdebRERiStO0A8GtqW8rojKUq0GpkXPvwP0MrP+Md+LmV1vZuVmVl5ZWRm37iIiEkOcoLc0Za7O6zuBC83sPeBC4DOgJuZ7cc7Ndc6VOefKCgsLY1RJRETi6hpjmQrgtJTXRcD21AWcc9uBKwDMrCcwzTm3z8wqgLF13rvsBOorIiLNFKdHvwI4y8xKzCwPmA4sTF3AzAaYWeKzfgLMi56/Aow3s37RSdjxUZmIiLSTJoPeOVcD3IIP6PXAAufcOjObbWb/HC02FthgZh8BJwNzovfuBu7D7yxWALOjMhERaSfmXL0h84wqKytz5eXlma6GiEhWMbOVzrmydPP0y1gRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcDFCnozm2BmG8xso5ndlWb+6Wa21MzeM7M1ZjYpKi82syozWxVNj7Z2A0REpHFdm1rAzHKAR4BLgApghZktdM59kLLYLGCBc+73ZjYE+CtQHM37xDk3snWrLSIiccXp0Y8GNjrnNjnnjgDzgal1lnFA7+h5H2B761VRRERORJygHwxsS3ldEZWl+jnwPTOrwPfmb02ZVxIN6bxuZv813QrM7HozKzez8srKyvi1FxGRJsUJektT5uq8vgp4wjlXBEwCnjSzLsAO4HTn3DnAHcD/MbPedd6Lc26uc67MOVdWWFjYvBaIiEij4gR9BXBayusi6g/NXAcsAHDOvQXkAwOcc4edc7ui8pXAJ8A/nmilRUQkvjhBvwI4y8xKzCwPmA4srLPMp8A4ADM7Gx/0lWZWGJ3MxczOBM4CNrVW5UVEpGlNXnXjnKsxs1uAV4AcYJ5zbp2ZzQbKnXMLgX8BHjOz2/HDOjOcc87MLgBmm1kNcBS40Tm3u81aIyIi9ZhzdYfbM6usrMyVl5dnuhoiIlnFzFY658rSzdMvY0VEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAqegFxEJnIJeRCRwCnoRkcAp6EVEAhcr6M1sgpltMLONZnZXmvmnm9lSM3vPzNaY2aSUeT+J3rfBzC5tzcqLiEjTuja1gJnlAI8AlwAVwAozW+ic+yBlsVnAAufc781sCPBXoDh6Ph0YCpwKvGZm/+icO9raDRERkfTi9OhHAxudc5ucc0eA+cDUOss4oHf0vA+wPXo+FZjvnDvsnNsMbIw+T0RE2kmcoB8MbEt5XRGVpfo58D0zq8D35m9txntFRKQNxQl6S1Pm6ry+CnjCOVcETAKeNLMuMd+LmV1vZuVmVl5ZWRmjSiIiElecoK8ATkt5XURyaCbhOmABgHPuLSAfGBDzvTjn5jrnypxzZYWFhfFrLyIiTYoT9CuAs8ysxMzy8CdXF9ZZ5lNgHICZnY0P+spouelm1s3MSoCzgHdaq/IiItK0Jq+6cc7VmNktwCtADjDPObfOzGYD5c65hcC/AI+Z2e34oZkZzjkHrDOzBcAHQA1ws664aaGqKujSBbp1y3RNRCTLmM/jjqOsrMyVl5dnuhodw9at8O//Di++CEuXQo8ecOedcMst0KtXpmsnIh2Ima10zpWlm6dfxnYkR4/C22/D3XdDaSkUF8PNN8Mnn8BNN8E3vwk//akvv/9+2L8/0zUWkSygoM+0Awfg2Wfh2mth0CD4p3+CX/4S+veHhx6CDRvgo4/gV7/yPfsVK3zg3323D/w5cxT4HdmuXfD887BuHXSwo2fpPDR0kwmbN8OiRT64ly2D6mro1w8mToQpU+DSS/3rxqxcCffe6z+jXz+44w649Vbo06ddmiANcA4+/NBvl0WL4M03obbWzyspgcmT/Ta+8ELIy8tsXSUojQ3dKOjbQ2JI5sUX/fRBdPeIb3wj+cX/5jeha5PnxutbuRJmz4aFC6FvXx/4P/qRAr89HTkC//Efye27aZMvHzHCb9uLL06G/5IlcOiQP8cyfryfP3EiDByY2TZI1uscQX/4MFx3HZx6qh8CqfvYo0frV7Yx+/bBK6/4Xt1f/+oP4bt2hQsu8F/uyZPha19rvfW9+64P/Bde8IF/++0+8Pv2bb11SNIXX/jtumiR38779/srosaN89t28mQ47bT67/vqKx/2iR7/jh1gBmPGJHf6w4b5MpFm6BxB//e/+17x9u0+9Ovq3Tv9DqDuY8+eLa/8xo3JIZk33oCaGj/WPmmS/xJfemnb97Tfe88H/vPP+3XdfjvMnKnAP1HO+XH2xPZ96y1fNmhQMtjHjWteh8I5v4NetMhPiX/3Z5yR/MyxYyE/v02aJGHpHEGf4Bzs3esDf/t232Nq6PHQofrv79Ur3g6hVy8f5H/7W7J39uGH/jOGDk32zsaMgZyclrenpVat8oH/3HM+8G+7zU8K/PgOH4bXX0+G+5YtvnzUqORR2ahR/vcNrWH7dn+U8OKLsHix/+1Ejx5wySV+fZMmwSmntM66JDidK+jjSuwQGtsRJB6rquq/v2dPf3h94ADk5vqe15QpcNllcOaZbV//uFav9oH/l7/4o5pE4Dd1srez2rkzGbavvgoHD8JJJ/lx9smT/fYd3A735auq8r+dSHQiKip8+ejRyU7EiBEa4pFjFPQnwjk/3t7QEcHFF/uTah39B0xr1vjAf/ZZH/gzZ/rALyjIdM0yyzl4//1kr335cl82eHCy1/7tb/uwz2QdV69ODvG8844vKypKDvFkuo6ScQp6SVqzBu67D555xu+cZs704/iZDPxDh2D37vZbXyLcE73lTz/15dnSW/78c/+L6UWL/FHHl18mjzoSR5WnnprpWko7U9BLfe+/7wP/z3/2gf+jH/lLM1sz8A8dijc01p4hn6p79+Qljtk6/n3o0PHnEbZu9eXnnnv8eYSOutOSVqOgl4atXZsM/J49/Y+u7rjDXy3UkKoqH9CJsG4owPfsqf/erl39yey6J7gHDGi9k5pxnH56eFe0OOe3ZyL0337bl516qu/lT5nirwzq3j3TNZU2oKCXpq1b5wN/wQJ/pcfNN/sQThfie/fWf39ubvqrk+qW9e/fvoHemVVWHn+t/4EDfseWeq1/UVGma9mxOOc7KIl/67t2te+tK/r390eZLaCgl/hSA985/zP9OJebFhQowDuyI0f8bzsSv97dvNmXjxyZHOIpKwt3GyYCPM5l1+l+h9Nezj/fH4m1gIJemm/nTn/9f0GBxndD4xysX58c4vnb3/z9eE4+OTnEc8kl7f9r8pZwzp/jaSq8GwrwPn0a78AUFrbvzi8/3/9grgUU9CLSsF274KWXfPC//LK/nLhbN7joouRVPC0MnxZzztcrToAfOVL//X37xjsSDeh8hYJeROKprvY3aEv09jdu9OXDh/vQnzIFzjuv5b/2rq2NH+DV1fXf37evD+mmArwT/qZAQS8izeec/78QEr83+M//9HdiLSz0vfzJk5M/Fqyt9Td6ixPgNTX119WvX9Ph3UkDPC4FvYicuN27/dU7L77oh3r27vVXWw0c6H/ElS7ACwriBXhIl7lmSGNB34IboItIp1RQAFdd5aeaGv+fqixa5C/jTDeccsopCvAOQkEvIs3Xtav/X7IuvDDTNZEYAr1oVkREEhT0IiKBU9CLiAROQS8iEjgFvYhI4BT0IiKBU9CLiAROQS8iErgOdwsEM6sEtma6HjENAL7IdCXaUMjtU9uyV8jtO5G2neGcK0w3o8MFfTYxs/KG7i0RgpDbp7Zlr5Db11Zt09CNiEjgFPQiIoFT0J+YuZmuQBsLuX1qW/YKuX1t0jaN0YuIBE49ehGRwCnoRUQCp6BvBjPbYmbvm9kqMyuPygrMbLGZfRw99st0PeMws3lmttPM1qaUpW2Leb81s41mtsbMRmWu5vE00L6fm9ln0fZbZWaTUub9JGrfBjO7NDO1jsfMTjOzpWa23szWmdnMqDzrt18jbcv6bWdm+Wb2jpmtjtp2b1ReYmbLo+32tJnlReXdotcbo/nFLV65c05TzAnYAgyoU/avwF3R87uAX2a6njHbcgEwCljbVFuAScBLgAFjgOWZrn8L2/dz4M40yw4BVgPdgBLgEyAn021opG2DgFHR817AR1Ebsn77NdK2rN920d+/Z/Q8F1gebY8FwPSo/FHgh9Hzm4BHo+fTgadbum716E/cVOAP0fM/AJdnsC6xOefeAHbXKW6oLVOBPzrvbaCvmQ1qn5q2TAPta8hUYL5z7rBzbjOwERjdZpU7Qc65Hc65d6PnB4D1wGAC2H6NtK0hWbPtor//wehlbjQ54NvAM1F53e2W2J7PAOPMzFqybgV98zjgVTNbaWbXR2UnO+d2gP9HCgzMWO1OXENtGQxsS1mugsa/fB3ZLdHwxbyUYbasbV90OH8OvncY1Par0zYIYNuZWY6ZrQJ2AovxRyB7nXM10SKp9T/Wtmj+PqB/S9aroG+ebznnRgETgZvN7IJMV6idpOtFZON1ub8H/gEYCewA/ldUnpXtM7OewLPAbc65/Y0tmqasQ7cvTduC2HbOuaPOuZFAEf7I4+x0i0WPrdY2BX0zOOe2R487gefwG+rzxGFw9LgzczU8YQ21pQI4LWW5ImB7O9fthDnnPo++aLXAYyQP8bOufWaWiw/CPznn/hIVB7H90rUtpG0H4JzbCyzDj9H3NbOu0azU+h9rWzS/D/GHI4+joI/JzHqYWa/Ec2A8sBZYCFwTLXYN8EJmatgqGmrLQuC/R1dvjAH2JYYIskmdcenv4Lcf+PZNj65yKAHOAt5p7/rFFY3T/m9gvXPuVymzsn77NdS2ELadmRWaWd/o+UnAxfhzEEuBK6PF6m63xPa8Evh/Ljoz22yZPhOdLRNwJv7s/mpgHXB3VN4fWAJ8HD0WZLquMdvzf/GHwNX4nsN1DbUFfwj5CH488X2gLNP1b2H7nozqvyb6Eg1KWf7uqH0bgImZrn8Tbfsv+EP4NcCqaJoUwvZrpG1Zv+2AUuC9qA1rgf8ZlZ+J3zltBP4MdIvK86PXG6P5Z7Z03boFgohI4DR0IyISOAW9iEjgFPQiIoFT0IuIBE5BLyISOAW9iEjgFPQiIoH7/xiNJRXMhCsRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   6,   2],\n",
       "       [  0, 110,  39],\n",
       "       [  0,  27, 152]], dtype=int64)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = model2.predict(X_val1)\n",
    "confusion_matrix(y_val1, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdIAAAEYCAYAAADoE3fkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5zd073/8dc7QS5FlOAMLYNGFSFqaNVdVenRutSt1SMp/aWKKqo96amj9HIOh3Oq5aDhkFJFcWiOtC5VgrhlErkqdYtWKHWLEEGSz++PtYZvdvbM7JnvXPZk3s/HYz9m7/Vda30/+5ud+cxa3+/+LkUEZmZm1jkDejsAMzOzvsyJ1MzMrAQnUjMzsxKcSM3MzEpwIjUzMyvBidTMzKwEJ1KzLiTpDElR5fGHbtjXPpJO6up+u0s+Dif0dhy1kLRa/rcc1duxWP1bpbcDMFsJLQD2rVLW1fYBDgHO64a+u8NOwNO9HUSNVgN+AMwDZvRuKFbvnEjNut6SiHigt4PoKElDIuKt7uq/rxwTSUN6OwbrWzy1a9bDJA2QNE7SE5LelvRnSaMr6vyjpNslvSjpdUkPSNqnsP0M4NvAxoXp4wl5212Srq/ob49cZ+v8ujG/PlLSFZJeA/6vUP9rkubm+J6R9N2K/raSdIukVyS9KelPko5v530vN7XbEqekr0p6WtIbkq6UNEjSjpIeymV3Sdqo0K4l9i/n+gvzcfpBlX3uJelBSYslvSDpQkmrVzkun5U0UdIbwAXAwlzl8sLxbcxtzpI0O8f2rKSrJP1DxX7nSTpX0sm5zquSrpG0VkW9dST9QtLzOcbHitP1tXxWrPd5RGrWDSRV/t9aGu/fj/N8YDTwQ2A68BngMkkvR8TNuc4mpMR2LrAM2A/4vaTdImIKcCkwAtgLOCi3+XsnQj0X+F/gUGBpjv07wL8B/wHcBWwP/EjSooi4ILebCDwKfAV4G/gosGYn9v9JYDjwTWAj4KfAW8An8v7fBH4OjGfF6fJzgJtJ09u7AT+Q9FJE/Hd+H1sCtwC3A18EPgycBWxapa//AS4nTZMvBn4F/BH4MTAp13k+/1yPdHyeA9Yl/UHzR0kjI2Jpoc/DgFnAWOBDwH/ldsfl+IaQju96wJmk4/mR/GhRy2fFeltE+OGHH130AM4Aospj77z9I6TEOLqi3RXA1Fb6HED6o/dW4LJC+bnAvCr17wKuryjbI8exdX7dmF/fWFFvTeAN4AcV5T8E/gYMJCW+AEZ28NgEcEJFnK8Bwwplv8n1diuUHZfLhlbEfltF/5cA84EB+fU1wOPAwEKdw3LbnSqOy08r+lo9l49p5z0NBDasEvM84ElglULZecDfCq+/nj8Lo1rpu8OfFT965+GpXbOutwDYoeLxYN72adIvxxslrdLyAO4ARkkaCCDpQ5J+KWk+sAR4l3Rx0eZdHOukitc7AR8ArquI74/A+qSR1SvAX4GLJR0uab0S+2+OiOKFWE8A7wD3VpQBbFDR9saK1/+b63wov96R9IdCcZR4A+l47lLRtvI4tErSfpLuk7Qg9/Vs3lT5b3NnRCwpvH4EWE/Savn1XsDDEdHaxUw1fVas93lq16zrLYmI5la2DSeNYlq7irdB0nOkqdM1gNNJieRN0qiwTNKq5oUq8QHMbaX+hyPimXy+9ifAZcAQSVOAEyPi4Q7u/7WK1+8ACyNiWUUZwOCKui+28roB+Ev+udz7i4ilkl4G1q5oW3kcqpK0A+nf5kbSNPGLpNHoA1Xiq/beRLoi+B1gHd6fLq6m3c8K7ydx60VOpGY96xXSKGZn0mij0oukKb3tgP0i4paWDar9atLFpF/WRZWJo0XlOoqv5J/7Uz25PAYQEY8CX5S0KrArcDYwSdKHKpJgd6r8o6Ll9fOFn8vVyaO4dXj/fbaodT3Jg0jnog+PPM8qaeNaA67wMsufD61Uy2fF6oATqVnP+iNplDEsIm6vVqGQMN8ulG1M+oU6q1D1HVYcBUEapexWUfaZGuO7n3SxzwYR0e50Z0S8S7rQ5r+AXwNrsWKS6i4HARcVXh9MSp4to7QHgYMk/Uthevdg0u+94tRxNa2NgocA77Yk0ezIjgae3QEcKmmbiJhVZXu7nxWrD06kZj0oIh6TdDFwjaT/AJpJv6y3AjaPiK+Rrt58FvhPSf9KmuI9k3QhTdGjwPqSxgBzgJciYh5p2vEYST8lnfvbE/hsjfG9pvTVmp/l5H036WKnzYE9I+IgSduQLnS6FngK+CDwz8DMiOipJAqwlaRfkM577gYcA3yrMCL+MfAwcJOki0jnTs8Gbo2I+9vqOCLekfQ0cJikOaRR/izSFcAnSTqPdFX1p0hXLnfGFcDxwG35mD9Gulp784gYV+NnxepBb1/t5IcfK9ODdNXuS+3UEXAS6Tzk26SpwsnAUYU6OwAPkUaHjwNjgAmki3Na6gwmfWWj5TzdhMK275EuCFpI+irHF6h+1e7+rcT4FWBa3v+rpNHdKXnbesCVpCS6mHQ179XARu2872pX7VZeXbzC8aP1K46PzPtdmI/hmYAq2n46x744H6cLgdVb67ui7T6k5Lk412nM5d/Nx/ZN4A+kryFVvrd5wLkV/Y3J9Yr7X4d0tfGLeT+Pks411/xZ8aP3H8r/WGZmfUK+McLTwOfD36W0OuCvv5iZmZXgRGpmZlaCp3bNzMxK8IjUzMysBH/9pZ8YPnx4NDY29nYYZmZ9yrRp016KiHXbquNE2k80NjbS3NzaXevMzKwaSc+0V8dTu2ZmZiU4kZqZmZXgRGpmZlaCE6mZmVkJTqRmZmYlOJGamZmV4ERqZmZWghOpmZlZCb4hQz8xe/4CGsdN6u0wzMx61Lyz/rHb9+ERqZmZWQlOpGZmZiU4kZqZmZXgRNpNJM2TNLwT7SZIOqQD9RslzenofszMrGs4kZqZmZXgRNoFJN0kaZqkuZLGVtl+lKRZkmZKujKXbSzpjlx+h6SNCk12k3SfpKdaRqdKzpE0R9JsSYf30NszM7M2+OsvXePoiHhF0hBgqqQbWjZI2gr4PrBzRLwkae286QLgioj4paSjgZ8DB+ZtDcAuwBbAROB64GBgFLAtMDzv5+4eeG9mZtYGj0i7xomSZgIPAB8GRhS27QVcHxEvAUTEK7l8J+DX+fmVpMTZ4qaIWBYRjwDr57JdgKsjYmlEvABMBnZoKyhJYyU1S2peumhBibdnZmatcSItSdIewN7AThGxLfAwMLhYBYgauirWebuiffFnzSJifEQ0RUTTwKHDOtrczMxq4ERa3jDg1YhYJGkL4JMV2+8ADpO0DkBhavc+4Ij8/Ejg3nb2czdwuKSBktYFdgMe6oo3YGZmnedzpOXdAhwraRbwGGl69z0RMVfST4DJkpaSRqxjgBOByyR9B/g78NV29nMjaTp4Jmn0+t2I+Jukxq57K2Zm1lGKqGXW0fq6QQ0jomH0eb0dhplZjyp7r11J0yKiqa06nto1MzMrwYnUzMysBJ8j7SdGbjiM5h5YTsjMrL/xiNTMzKwEJ1IzM7MSnEjNzMxK8DnSfmL2/AU0jpvU22GYWRvKflXDeodHpGZmZiU4kZqZmZXgRGpmZlaCE2knSRoj6YKydaq0OUnS0HLRmZlZT3EirT8nAU6kZmZ9hBNpgaQPSJokaaakOZIOlzRP0vC8vUnSXVXaTZB0saR7JP1Z0v6FzRtIukXS45L+o9Dmorzo9lxJZ+ayE4ENgDsl3ZnL9pF0v6Tpkq6TtHouP0vSI5JmSTq3+46KmZm1xV9/Wd6+wHMR8Y8AkoYBZ9fYthHYHdiMlAg/kstHAduRFut+TNL5EfFX4PsR8YqkgcAdkraJiJ9LOgXYMyJeygn8NGDviHhT0j8Dp+Tp4oOALSIiJK1VLSBJY4GxAAPXXLejx8LMzGrgEenyZgN7Szpb0q4RsaADbX8TEcsi4nHgKWCLXH5HRCyIiMXAI8DGufwwSdNJ65NuBWxZpc9P5vIpkmYAo3P714HFwKWSDgYWVQsoIsZHRFNENA0cOqwDb8XMzGrlEWlBRPxZ0vbA54B/l3QbsIT3/+AY3FbzVl6/XShbCqwiaRPgVGCHiHhV0oRW+hZwe0R8aYUN0o7Ap4EjgBOAvdp6b2Zm1j08Ii2QtAGwKCJ+BZwLfByYB2yfq3yxjeaHShogaTNgU+CxNuquCbwJLJC0PrBfYdtCYI38/AFg55ZpYklDJW2ez5MOi4jfkS5OGtWBt2lmZl3II9LljQTOkbQMeBf4BjAE+B9J/wI82Ebbx4DJwPrAsRGxWFLVihExU9LDwFzSNPCUwubxwO8lPR8Re0oaA1wtaVDefhop2f5W0mDSqPXkTr1bMzMrTRGVM5LWUXlq9uaIuL63Y2nNoIYR0TD6vN4Ow8za4Hvt1h9J0yKiqa06nto1MzMrwSPSfqKpqSmam5t7Owwzsz7FI1IzM7Nu5kRqZmZWghOpmZlZCf76Sz8xe/4CGsdN6u0wzPotX5G78vKI1MzMrAQnUjMzsxKcSM3MzEpwIu1jJN0lqanwulHSnN6MycysP3MiNTMzK8GJtE7lkeajkn4paZak6yUN7e24zMxsef76S337KHBMREyRdBlwXC6/StJb+flqwLJqjSWNBcYCDFxz3e6O1cysX/KItL79NSJallj7FbBLfn5kRIyKiFGkRciriojxEdEUEU0Dhw7r7ljNzPolJ9L6VrmigFcYMDOrM06k9W0jSTvl518C7u3NYMzMbEVOpPXtT8BoSbOAtYGLejkeMzOr4IuN6tuyiDi2omyP4ouImAds3VMBmZnZ8jwiNTMzK8Ej0jrV1SPNkRsOo9mrT5iZdTmPSM3MzEpwIjUzMyvBidTMzKwEnyPtJ2bPX0DjuEm9HYZZj5rn6wKsB3hEamZmVoITqZmZWQlOpGZmZiU4kXYhSWdIOrUL+/udpLXy47j2W5iZWU9zIq1jEfG5iHgNWIv31yI1M7M64kRakqTvS3pM0h9IC3EjaTNJt0iaJukeSVvk8gmSfi7pPklPSToklzdIulvSDElzJO2ay+dJGg6cBWyWt58j6UpJBxRiuErSF3r8zZuZmb/+Uoak7YEjgO1Ix3I6MA0YDxwbEY9L+gRwIbBXbtZAWqB7C2AicD3wZeDWiPiJpIHA0IpdjQO2zgt5I2l34GTgt5KGAZ8CRleJbywwFmDgmut21ds2M7MCJ9JydgVujIhFAJImAoNJie06SS31BhXa3BQRy4BHJK2fy6YCl0laNW+f0dZOI2KypP+WtB5wMHBDRCypUm88KakzqGGEFwU3M+sGntotrzJBDQBei4hRhcfHCtvfLjwXQETcDewGzAeulHRUDfu9EjgS+CpweaejNzOzUpxIy7kbOEjSEElrAJ8HFgFPSzoUQMm2bXUiaWPgxYi4BPgf4OMVVRYCa1SUTQBOAoiIuWXfiJmZdY4TaQkRMR24FpgB3ADckzcdCRwjaSYwFzigeg/v2QOYIelh4IvAzyr28zIwJV+IdE4uewH4Ex6Nmpn1KkX41FlfJGkoMBv4eEQsaK/+oIYR0TD6vO4PzKyO+F67VpakaRHR1FYdj0j7IEl7A48C59eSRM3MrPv4qt0+KCL+AGzU23GYmZkTab8xcsNhNHuay8ysy3lq18zMrAQnUjMzsxI8tdtPzJ6/gMZxk3o7DLOa+Ypb6ys8IjUzMyvBidTMzKwEJ1IzM7MSnEjNzMxK6JZEKmktScfVUK9R0pdrrDenC+I6Q9Kp+fkWeaHshyVtVrbv3GfLQtxIuq+TfTRJ+nl7/ZuZWX3orhHpWkC7iRRoJC1q3RsOBH4bEdtFxJO1NJBU81XOEfGpzgQVEc0RcWJn2pqZWc/rcCKV9EFJ27RT7SxgszziOycvJXZOXr1ktqTDC/V2zfVOziPPeyRNz482k5GkBkl35/ZzJO2ay98o1DlE0oSKdp8jLUH2NUl3Vo54JZ0q6Yz8/C5J/yZpMvCtin7WkXRbHtX+gry+aDGG1t67pIMk/SFvb5D0Z0n/IGkPSTfX0P9XJD2U3/svJA1s59/EzMy6QU2JNCeTNSWtDcwELpf0X200GQc8mRe1/g5wMDAK2BbYGzhHUkOud0+u91PgReAzEfFx4HCg6hRnwZeBWyOipe8ZtbyfiPgdcDHw04jYs4Yma0XE7hHxnxXlPwDujYjtgIlUv/9t1fceETcCfwOOBy4BfhARf6ulf0kfIx2fnfN7X0paum05ksZKapbUvHSR721vZtYdap2qHBYRr0v6GnB5RPxA0qwO7GcX4OqIWAq8kEd3OwCvV9RbFbhAUkty2LydfqcCl0laFbgpImpKpJ1wbSvlu5ESJRExSdKrVeq09t4nAt8E5gAPRMTVHej/08D2wFRJAENIf4QsJyLGA+MhLaNWw/s0M7MOqnVqd5U8gjwMuLkT+1H7VQA4GXiBNHprAlZrq3JE3E1KNvOBKyUd1bKpUG1wDftdwvLHorLNm22F0U7fbb33DYFlwPqSWvu3qNa/gF/mkfyoiPhoRJzRThxmZtYNak2kPwRuJU3XTpW0KfB4G/UXAmsUXt8NHC5poKR1ScnvoSr1hgHPR8Qy4J+ANs/7SdoYeDEiLgH+B/h43vSCpI/l5HRQDe/vBWC9fE5yELB/DW1a3teROZb9gA+2UmeF954vXLqcND39J+CUDvR/B3CIpPXytrXzsTAzsx5W09RuRFwHXFd4/RTwxTbqvyxpSr6A5/fAd4GdSOdXA/huRPxN0svAEkkzgQnAhcANkg4F7qTtkSDAHsB3JL0LvAG0jEjHkUbOfyVNna7ezvt7V9IPgQeBp0mLZtfiTOBqSdOBycBfqtS5kerv/XTS+eF7JM0gTdNW3gy3av8R8Yik04Db8h8L75LOtT5TY9xmZtZFFNH+qTNJmwMXAetHxNb5qt0vRMSPuztA6xqDGkZEw+jzejsMs5r5pvVWDyRNi4imturUOrV7CfA90siHiJgFHFEuPDMzs76v1qt2h0bEQ/kK0RZLuiEe6yYjNxxGs//CNzPrcrWOSF9Suo1eQLrJAfB8t0VlZmbWR9Q6Ij2e9H3ELSTNJ12Qs8INAMzMzPqbdhNpviq0KSL2lvQBYEBELOz+0MzMzOpfu4k0IpZJOgH4TUS093UUq1Oz5y+gcVzlt2vMeoavwLWVWa3nSG/PN3L/cP7y/9r5vrtmZmb9Wq3nSI/OP48vlAWwadeGY2Zm1rfUemejTbo7EDMzs76o1mXUjqr2qHUnkk6U9CdJV3U+1PIq1voclNcDnaH310ct2/+E/NUgJF0qactO9nNfe/2bmVl9qHVqd4fC88GkZbymA1fU2P44YL+IeLpYKGmViOitGztsB6ya1/OsSUfijYivdTawiGhzQXMzM6sfNY1II+Kbhcf/IyWhNpc4ayHpYtK51ImSTpZ0hqTxkm4DrsiropwjaaqkWZK+Xmj7nUL5mVX6HphHaXMkzZZ0ci6/S1JTfj5c0ryKdusBvwJG5RHpZpLmSRqetzdJuis/Xy7ein4k6QJJj+Qbzq9X2FaM4Us5vjmSzs5lG0t6PMc3QNI9kvbJ296oof/tJU2WNE3SrUrL3JmZWQ+rdURaaREwopaKEXGspH2BPSPiJUlnkBal3iUi3pI0FlgQETsoLWE2JSetEfmxI2n9zYmSdstrkLYYBWwYEVsDSFqrxpheVFqk/NSI2D+3bavJe/FWlB8EfBQYCawPPAJcVqwgaQPg7NzHq6QVWw6MiJtyUr2YtOrMIxFxWy39Ky1kfj5wQET8PU9N/4T3Lwpr2fdYYCzAwDXXbfugmJlZp9SUSCX9H+8vMD0A2JLCsmqdMLGQlPYBtimc+xtGSqD75MfDuXz1XF5MpE8Bm0o6H5gEVCairjKxShKFtLbo1RGxFHhO0h+r1NkBuCsi/g6QzxPvBtwUEZcqLRl3LOmPglr7/yiwNelrSZDWbV3hlo0RMZ50RyoGNYxof5kfMzPrsFpHpOcWni8BnomIZ0vst3hjBwHfjIhbixUkfRb494j4RWudRMSrkrYFPkv6as5hpFHZEt6fth5cY0xttWnrRhTtJahWh7qShgIfyi9XJy10Xkv/AuZGxE7t7NvMzLpZrTdk+FxETM6PKRHxbMu5vi5wK/CNPF2JpM3zrQhvBY6WtHou3zCf23xPPqc5ICJuAP4V+HjeNI80lQpQ61WuxTatLlpe4W7giHyutgHYs0qdB4Hd87nQgcCXSIt0Q5ryvQo4nbRUXa39PwasK2knAEmrStqqxpjNzKwL1ZpIP1OlbL8uiuFS0rm/6ZLmAL8AVsnnC38N3C9pNnA9sEZF2w2BuyTNACaQ1kyFNIL+Rv4ayfAa4zgT+Jmke4ClNba5EXgcmE1a+HxyZYWIeD7HdScwE5geEb+VtDtp2vfsiLgKeEfSV2vpPyLeIf2BcLakmcAMwFf6mpn1AkW0PjMp6Rukr65sCjxZ2LQGMCUivtK94VlXGdQwIhpGn9fbYVg/5XvtWl8laVpENLVVp71zpL8Gfg/8OzCuUL4wIl4pGZ+ZmVmf1+aIdIXK6RzlexfiRMRfuiMo63pNTU3R3Nzc22GYmfUptYxIa71F4OclPU5a0Hsy6cKc35eO0MzMrI+r9WKjHwOfBP6cb2D/aWBKt0VlZmbWR9SaSN+NiJeBAZIGRMSdVL+BgJmZWb9S6w0ZXsvf57wHuErSi6QbGFgfMXv+AhrHTertMKwH+ApZs55V64j0ANL9dU8CbiF9Febz3RWUmZlZX1Hrwt5vStoYGBERv8y3thvYvaGZmZnVv1qv2v1/pDsLtdz3dkPgpu4KyszMrK+odWr3eGBn4HWAiHicwtqY/UVe+3SFe/dKasy3N+xIXxtIur6Vbe+tZWpmZvWt1kT6dr6/KwCSVqH9VU+sFZJWiYjnIqLWG+qbmVmdqjWRTpb0L8AQSZ8hrUX6f90XVn2QdJSkWZJmSroyF+8m6T5JT7UyOh0s6XJJsyU9LGnPXD5G0nV5bdfbiqNYSUMkXZP3dS0wpNDfPpLulzQ9t29ZDecsSY/kNudWxmFmZj2j1q+/jAOOIa1C8nXgd6RVW1ZaeVmy7wM7R8RLktYG/gtoAHYBtgAmks4dFx0PEBEjJW1BSpqb5207AdtExCuSGgttvgEsiohtJG0DTM8xDAdOA/bOF3z9M3CKpAuAg4AtIiIkrdXKexgLjAUYuOa6JY6GmZm1ps1EKmmjiPhLRCwjrZdZbc3MldVewPUR8RJATn4AN+Xj8Yik9au02wU4P7d5VNIzQEsivb2Vm/3vBvw8t5klaVYu/ySwJTAl73s14H7SuerFwKWSJgE3V3sDETEeGA9p9ZcOvHczM6tRe1O7712ZK+mGbo6l3ojq54HfrqhTrV1r3mxjW7V9iZR8R+XHlhFxTEQsAXYEbgAOJH2318zMekF7ibSYFDbtzkDq0B3AYZLWAchTu7W4Gzgyt9kc2Ah4rANttga2yeUPADtL+kjeNlTS5vk86bCI+B3pJhm+XaOZWS9p7xxptPJ8pRcRcyX9hHSh1VLg4RqbXghcLGk26TaKYyLi7Tw125qLgMvzlO4M4KEcw98ljQGuljQo1z0NWAj8VtJg0h87J3fs3ZmZWVdpcz3SnEDeJP2yHkK6TSD5dUTEmt0eoXWJQQ0jomH0eb0dhvUA32vXrOvUsh5pmyPSiPBtAM3MzNpQ6/dIzczMrIpav0dqfdzIDYfR7Ck/M7Mu5xGpmZlZCU6kZmZmJXhqt5+YPX8BjeMm9XYY1o18ta5Z7/CI1MzMrAQnUjMzsxKcSM3MzEpwIjUzMyuh3yVSScdKOqpK+XsLbXey37sktXkbKTMzW/n06at2le4Er7w+aE0i4uJuDKlXSVolL7FmZmY9pM+NSPPI8U+SLgSmAx+WtI+k+yVNl3RdXmYMSWdJekTSLEnn5rIzJJ2an28vaaak+4HjC/sYI+mCwuubJe2Rn18kqVnSXEln1hBvtRgmSDqkUOeN/HOApAtz3zdL+l1LPUmnS5oqaY6k8fmPiJaR8L9Jmgx8q9TBNTOzDutziTT7KHBFRGxHWp3mNGDviPg40AycktcPPQjYKiK2AX5cpZ/LgRMjYqcO7Pv7eSWAbYDdJW3TWsUaYyg6GGgERgJfA4pxXRARO0TE1qSVePYvbFsrInaPiP+s2P/YnPSbly5aUOPbMzOzjuirifSZiHggP/8ksCUwRdIMYDSwMfA6sBi4VNLBvL8EHACShpES0ORcdGWN+z5M0nTS+qRb5X23ps0YqtgFuC4ilkXE34A7C9v2lPRgXud0r7zvFtdW6ywixkdEU0Q0DRw6rJ1dm5lZZ/TVc6RvFp4LuD0ivlRZSdKOwKeBI4ATSAmo2K61xViXsPwfGYNzf5sApwI7RMSrkia0bKsmIpa0EsN7/ecp2tUKMa0gL+B9IdAUEX+VdEbFft+s1s7MzLpfXx2RFj0A7CzpIwCShkraPJ8nHRYRvwNOAkYVG0XEa8ACSbvkoiMLm+cBo/I5yw8DO+byNUlJa4Gk9YH92gqsjRjmAdvn5wcAq+bn9wJfzPtdH9gjl7ckzZdyn++dXzUzs97VV0ek74mIv0saA1wtaVAuPg1YCPw2j+YEnFyl+VeByyQtAm4tlE8BngZmA3NIFzURETMlPQzMBZ7K9dqyRisxXJLLHwLu4P0R5Q2k0esc4M/Ag8CCiHhN0iU5nnnA1Hb2a2ZmPUQRrc1uWm+QtHpEvCFpHeAhYOd8vrSUQQ0jomH0eeUDtLrlm9abdT1J0/IFpq3q8yPSldDNktYinTf9UVckUTMz6z5OpHUmIvbojn5HbjiMZo9YzMy63MpwsZGZmVmvcSI1MzMrwYnUzMysBJ8j7Sdmz19A47hJvR2GtcJX3Jr1XR6RmpmZleBEamZmVoITqZmZWQlOpDWQdKyko/LzMZI2aKPuDyXt3d1xVJQ3SprTHfs0M7O2+WKjGkTExYWXY0j3wn2usp6kgRFxeg/FYWZmdcAj0gqSjpI0S9JMSVfmsjMknSrpEKAJuErSDElDJM2TdLqke4FDJU3I9ZC0g6T7cl8PSVqjYl+rS7pD0nRJsyUdUEsc+fn2edv9wPE9c3TMzKySR6QFktShftoAABBLSURBVLYCvk+6UfxLktYubo+I6yWdAJwaEc25DcDiiNglv943/1yNtOD24RExVdKawFsVu1wMHBQRr0saDjwgaSJpsfBW48guB74ZEZMlndPK+xkLjAUYuOa6HT4eZmbWPo9Il7cXcH1EvAQQEa/U2O7aKmUfBZ6PiKm5r9cjYklFHQH/JmkW8AdgQ2D99uKQNAxYKyIm56IrqwUVEeMjoikimgYOHVbjWzEzs47wiHR5AjqzrtybVcpq6etIYF1g+4h4V9I80iLe7bXtbJxmZtbFPCJd3h3AYXktUFqZUl1IWrC7PY8CG0jaIfe1hqTKP1yGAS/mJLonsHEtcUTEa8ACSbvkoiNriMfMzLqBR6QFETFX0k+AyZKWAg+TrtItmgBcLOktYKc2+npH0uHA+ZKGkM6P7g28Uah2FfB/kpqBGaTkW2scXwUuk7QIuLUTb9fMzLqAIjxD2B8MahgRDaPP6+0wrBW+165ZfZI0LSKa2qrjqV0zM7MSPLXbT4zccBjNHvWYmXU5j0jNzMxKcCI1MzMrwYnUzMysBJ8j7Sdmz19A47hJvR2GVeErds36No9IzczMSnAiNTMzK8GJ1MzMrISVNpFKapQ0p4Y6Xy68bpL08/x8jKQLujG+H0rau0r5HpJuzs+/IGlcfn6gpC27Kx4zM+uc/n6xUSPwZeDXAHmN0eae2HFEnF5DnYnAxPzyQOBm4JHujMvMzDqmz4xIJZ0t6bjC6zMkfVvJOZLmSJqdbxRf2bZR0j2SpufHp/Kms4BdJc2QdHJxNFjRfl1JN0iamh87d2AfSPpujm2mpLNy2QRJh+Tn+0p6VNK9wMGFdmMkXZD7+gJwTo51M0nTC/VGSJrWicNqZmYl9aUR6TXAecCF+fVhwL6kxDMK2BYYDkyVdHdF2xeBz0TEYkkjgKuBJmAccGpE7A9pWrWVff8M+GlE3CtpI9JqKx+rZR+S9iONJj8REYsql0STNBi4hLSY9xNUWSQ8Iu6TNBG4OSKuz+0WSBoVETNIK8FMqGwnaSwwFmDgmuu28tbMzKyMPpNII+JhSetJ2oC0GParEfEXSScDV0fEUuAFSZOBHYBZhearAhdIGgUsBTbv4O73BraU1PJ6TUlrRMTCGvaxN3B5RCzK7+OVir63AJ6OiMcBJP2KnPzacSnwVUmnAIcDO1ZWiIjxwHhIq7/U0KeZmXVQn0mk2fXAIcA/kEaoAGq9+ntOBl4gjVoHAIs7uN8BwE4R8VYn9iGgvSTWmSR3A/AD4I/AtIh4uRN9mJlZSX3mHGl2DXAEKZlen8vuBg6XNFDSusBuwEMV7YYBz0fEMuCfgIG5fCGwRg37vQ04oeVFHnVWam0ftwFHSxqa265d0e5RYBNJm+XXX2olhuVijYjFpCnmi4DLa3gPZmbWDfpUIo2IuaRkMj8ins/FN5KmcWeSRmffjYi/VTS9EBgt6QHSlOubuXwWsCRfBHRyG7s+kXS+c5akR4Bjq9Spuo+IuIV05W2zpBnAqRXvaTFpKndSvtjomVZiuAb4jqSHC0n3KtJo9rY2Yjczs26kCJ8666sknQoMi4h/ba/uoIYR0TD6vB6IyjrK99o1q1+SpkVEU1t1+to5Ussk3QhsRrra18zMeokTaR8VEQf1dgxmZuZE2m+M3HAYzZ5CNDPrcn3qYiMzM7N640RqZmZWgqd2+4nZ8xfQOG5Sb4fRb/nKXLOVl0ekZmZmJTiRmpmZleBEamZmVsJKnUglnSjpT5KukvQFSeO6qN83uqCPVuNp6V/SBpJalk0bJelzZfdrZmZda2W/2Og4YL+IeDq/ntibwRRFxETaiSciniPdoB/SmqtNwO+6OTQzM+uAlXZEKuliYFNgoqSTJY2RdEHe9ltJR+XnX5d0VX6+maRbJE2TdI+kLXL5JpLulzRV0o/a2OdNue3cvKh2S/m+kqbnm+PfkcuK8VTtX1KjpDmSVgN+SFrlZoakwyU9nle7QdIASU9IGt61R9HMzNqz0o5II+JYSfsCe0bES5LGFDaPBaZIehr4NvDJXD4eODYiHpf0CdKKLnsBPwMuiogrJB3fxm6PjohXJA0Bpkq6gfTHyiXAbhHxdJVl1Giv/4h4R9LpQFNEnACQk/yRwHmkxcNnRsRLtR0dMzPrKivtiLQtEfECcDpwJ/DtnPxWBz4FXJeXO/sF0JCb7AxcnZ9f2UbXJ0qaCTwAfBgYQUrSd7dML0fEK1Xa1dp/0WXAUfn50VRZk1TSWEnNkpqXLlpQY7dmZtYRK+2ItAYjgZeBDfLrAcBrEVFt0W5I6362StIepJHhThGxSNJdwGBA7bWtpf8VKkf8VdILkvYCPkEanVbWGU8aZTOoYYTXyzMz6wb9ckQqaUdgP2A74FRJm0TE68DTkg7NdSRp29xkCnBEfr5CwsqGAa/mJLoF708X3w/sLmmT3G+1qd1a+l9IWtS86FLgV8BvImJpK+3MzKwb9btEKmkQ6Zzl0fmq2G8Dl0kSKYkdk6dn5wIH5GbfAo6XNJWUMKu5BVhF0izgR6TpXSLi76Rzsv+b+722Stta+r8T2LLlYqNcNhFYnSrTumZm1jMU4Rm/vkpSE/DTiNi1vbqDGkZEw+jzeiAqq8b32jXrmyRNi4imtur053OkfVq+mcM3aH0q2MzMekC/m9pdWUTEWRGxcUTc29uxmJn1Zx6R9hMjNxxGs6cXzcy6nEekZmZmJTiRmpmZleBEamZmVoITqZmZWQlOpGZmZiU4kZqZmZXgRGpmZlaCE6mZmVkJTqRmZmYl+Kb1/YSkhcBjvR1HJwwHXurtIDqpr8buuHuW4+5ZHY1744hYt60KvkVg//FYeysY1CNJzX0xbui7sTvunuW4e1Z3xO2pXTMzsxKcSM3MzEpwIu0/xvd2AJ3UV+OGvhu74+5ZjrtndXncvtjIzMysBI9IzczMSnAiNTMzK8GJtI+StK+kxyQ9IWlcle2DJF2btz8oqbGw7Xu5/DFJn621z96MW9JnJE2TNDv/3KvQ5q7c54z8WK+O4m6U9FYhtosLbbbP7+cJST+XpDqK+8hCzDMkLZM0Km+rh+O9m6TpkpZIOqRi22hJj+fH6EJ5PRzvqnFLGiXpfklzJc2SdHhh2wRJTxeO96h6iTtvW1qIbWKhfJP8mXo8f8ZWq5e4Je1Z8fleLOnAvK3jxzsi/OhjD2Ag8CSwKbAaMBPYsqLOccDF+fkRwLX5+Za5/iBgk9zPwFr67OW4twM2yM+3BuYX2twFNNXp8W4E5rTS70PAToCA3wP71UvcFXVGAk/V2fFuBLYBrgAOKZSvDTyVf34wP/9gHR3v1uLeHBiRn28APA+slV9PKNatp+Odt73RSr+/AY7Izy8GvlFPcVd8Zl4Bhnb2eHtE2jftCDwREU9FxDvANcABFXUOAH6Zn18PfDr/BX4AcE1EvB0RTwNP5P5q6bPX4o6IhyPiuVw+FxgsaVAXx9eaMse7KkkNwJoRcX+k/71XAAfWadxfAq7u4tja0m7cETEvImYByyrafha4PSJeiYhXgduBfevleLcWd0T8OSIez8+fA14E2rybThcqc7yryp+hvUifKUifsbo53hUOAX4fEYs6G4gTad+0IfDXwutnc1nVOhGxBFgArNNG21r6LKtM3EVfBB6OiLcLZZfnaZh/7YYpu7JxbyLpYUmTJe1aqP9sO332dtwtDmfFRNrbx7ujbevleLdL0o6kEdaTheKf5Cnfn3bDH5Bl4x4sqVnSAy3To6TP0Gv5M9WZPmvRVb+zjmDFz3eHjrcTad9U7RdX5feYWqvT0fKuVCbutFHaCjgb+Hph+5ERMRLYNT/+qWSclcrE/TywUURsB5wC/FrSmjX2WVZXHO9PAIsiYk5hez0c7462rZfj3XYHaeR8JfDViGgZRX0P2ALYgTQN+c9lgqy22yplHYl7o0i33PsycJ6kzbqgz1p01fEeCdxaKO7w8XYi7ZueBT5ceP0h4LnW6khaBRhGOg/QWtta+iyrTNxI+hBwI3BURLz313pEzM8/FwK/Jk351EXceQr95RzfNNIoY/Nc/0Pt9NlrcRe2r/DXep0c7462rZfj3ar8B9Yk4LSIeKClPCKej+Rt4HLq63i3TEUTEU+Rzp9vR7op/Fr5M9XhPmvUFb+zDgNujIh3Wwo6c7ydSPumqcCIfFXcaqRfdhMr6kwEWq5YPAT4Yz43NBE4QulqzU2AEaSLMGrps9filrQW6ZfM9yJiSktlSatIGp6frwrsD8yha5WJe11JA3N8m5KO91MR8TywUNIn89ToUcBv6yXuHO8A4FDSuSdyWb0c79bcCuwj6YOSPgjsA9xaR8e7qlz/RuCKiLiuYltD/inSeca6Od75OA/Kz4cDOwOP5M/QnaTPFKTPWN0c74IVzv936niXvXLKj955AJ8D/kwa4Xw/l/0Q+EJ+Phi4jnQx0UPApoW238/tHqNw5WK1PuslbuA04E1gRuGxHvABYBowi3QR0s+AgXUU9xdzXDOB6cDnC3025f+kTwIXkO80Vg9x5217AA9U9Fcvx3sH0ojkTeBlYG6h7dH5/TxBmiKtp+NdNW7gK8C7FZ/vUXnbH4HZOfZfAavXUdyfyrHNzD+PKfS5af5MPZE/Y4PqJe68rRGYDwyo6LPDx9u3CDQzMyvBU7tmZmYlOJGamZmV4ERqZmZWghOpmZlZCU6kZmZmJTiRmtkKJL3Rw/trlPTlntynWVdxIjWzXpXvftNIusWcWZ+zSvtVzKy/krQHcCbwAjAK+F/Sl9W/BQwBDoyIJyVNABYDWwHrA6dExM2SBgMXkW6GsCSX3ylpDPCPpBtCfAAYCnxM0gzSSiE3ku45+4EcygkRcV+O5wzSLei2Jt0c4isREZJ2IN0g4gPA28CngUXAWaSbSwwC/jsiftHVx8n6NydSM2vPtsDHSPfgfQq4NCJ2lPQt4JvASbleI7A7sBlwp6SPAMcDRMRISVsAt0naPNffCdgmIl7JCfLUiNgfQNJQ4DMRsVjSCNJt3Jpyu+1ICfs5YAqws6SHgGuBwyNiar5v7VvAMcCCiNgh38puiqTbIi0haNYlnEjNrD1TI92rFklPArfl8tnAnoV6v4m0Ysnjkp4iraCxC3A+QEQ8KukZ0k37Ia8b2so+VwUukDQKWFpoA/BQRDyb45lBSuALgOcjYmre1+t5+z7ANpJa7vk6jHS/YydS6zJOpGbWnuK6r8sKr5ex/O+QyvuNtrZ8WYs329h2Mmk6eVvStRyLW4lnaY5BVfZPLv9mRNxaZZtZl/DFRmbWVQ6VNCCvR7kpaVGEu4EjAfKU7ka5vNJCYI3C62GkEeYy0nqnA9vZ96PABvk8KZLWyBcx3Qp8I69Ug6TNJX2gjX7MOswjUjPrKo8Bk0kXGx2bz29eCFwsaTbpYqMxEfF2WqFqObOAJZJmAhOAC4EbJB1KWo6rrdErEfGOpMOB8yUNIZ0f3Ru4lDT1Oz0vi/V30tJYZl3Gq7+YWWn5qt2bI+L63o7FrKd5atfMzKwEj0jNzMxK8IjUzMysBCdSMzOzEpxIzczMSnAiNTMzK8GJ1MzMrIT/D2TkaZKZdef9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importances(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
