{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de données\n",
    "\n",
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('beer_quality.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "4     53\n",
       "8     18\n",
       "3     10\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données en features et label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  \n",
       "0         9.4  \n",
       "1         9.8  \n",
       "2         9.8  \n",
       "3         9.8  \n",
       "4         9.4  \n",
       "...       ...  \n",
       "1594     10.5  \n",
       "1595     11.2  \n",
       "1596     11.0  \n",
       "1597     10.2  \n",
       "1598     11.0  \n",
       "\n",
       "[1599 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       5\n",
       "2       5\n",
       "3       6\n",
       "4       5\n",
       "       ..\n",
       "1594    5\n",
       "1595    6\n",
       "1596    6\n",
       "1597    5\n",
       "1598    6\n",
       "Name: quality, Length: 1599, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données en train et en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Classification Binaire \n",
    "\n",
    "## Création de nouvelle variable en fonction de la médiane de y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "#Calcul de la médiane\n",
    "statistics.median(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implémentation de ybin en fonction de la médiane \n",
    "\n",
    "ybin = []\n",
    "\n",
    "for i in y:\n",
    "    m = 6\n",
    "    if i < m:\n",
    "        ybin.append(0)\n",
    "        \n",
    "    else:\n",
    "        ybin.append(1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df.assign(ybin= ybin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>ybin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  ybin  \n",
       "0         9.4        5     0  \n",
       "1         9.8        5     0  \n",
       "2         9.8        5     0  \n",
       "3         9.8        6     1  \n",
       "4         9.4        5     0  \n",
       "...       ...      ...   ...  \n",
       "1594     10.5        5     0  \n",
       "1595     11.2        6     1  \n",
       "1596     11.0        6     1  \n",
       "1597     10.2        5     0  \n",
       "1598     11.0        6     1  \n",
       "\n",
       "[1599 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>ybin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  ybin  \n",
       "0         9.4     0  \n",
       "1         9.8     0  \n",
       "2         9.8     0  \n",
       "3         9.8     1  \n",
       "4         9.4     0  \n",
       "...       ...   ...  \n",
       "1594     10.5     0  \n",
       "1595     11.2     1  \n",
       "1596     11.0     1  \n",
       "1597     10.2     0  \n",
       "1598     11.0     1  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On cherche à prédire ybin, on supprime quality\n",
    "new_df.drop(\"quality\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.iloc[:, :11]\n",
    "y = new_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc=StandardScaler()\n",
    "\n",
    "#scaler = sc.fit(X)\n",
    "#X = scaler.transform(X)\n",
    "\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth' : np.arange(1,5),\n",
    "             'min_samples_split' : np.arange (1,5)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(clf, param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 907, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 241, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [       nan 0.68722373 0.68722373 0.68722373        nan 0.68722373\n",
      " 0.68722373 0.68722373        nan 0.69436659 0.69436659 0.69436659\n",
      "        nan 0.69974776 0.70064061 0.70064061]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(criterion='entropy'),\n",
       "             param_grid={'max_depth': array([1, 2, 3, 4]),\n",
       "                         'min_samples_split': array([1, 2, 3, 4])})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.005911111831665039s\n"
     ]
    }
   ],
   "source": [
    "model = grid.best_estimator_\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.0010313987731933594s\n",
      "0.6895833333333333\n",
      "0.7453083109919572\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "test_score = model.score(X_test, y_test)\n",
    "stop = time.time()\n",
    "print(f\"Inference time: {stop - start}s\")\n",
    "print(test_score)\n",
    "\n",
    "\n",
    "train_score = model.score(X_train, y_train)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[172,  45],\n",
       "       [104, 159]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 1\n",
    "model_a = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1), n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.19148826599121094s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model_a.fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.02193927764892578s\n",
      "0.7458333333333333\n",
      "0.8293118856121537\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "test_score = model_a.score(X_test, y_test)\n",
    "stop = time.time()\n",
    "print(f\"Inference time: {stop - start}s\")\n",
    "print(test_score)\n",
    "print(model_a.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import pylab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAYAAAAp8/5SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dfZzNdf7/8ceLlKQLQomKNhQZ1KQLXZBYIvqWNrqUSiVWV1uS7comlU1Ztm1+Vu22RVZXQmwklWiNpYhIshlsJBS5mvH+/fGayWCGM5efOec877fb3Dif85lzXnMcr3mf1+f9fr0thICIiCSuclEHICIiJUuJXkQkwSnRi4gkOCV6EZEEp0QvIpLglOhFRBLcQbGcZGbtgOeA8sDIEMLgve4fCrTKvlkJqBFCOMrMWgFDc516CtA1hPBWfs9VrVq1UKdOndh/AhERYe7cud+HEKrndZ8daB69mZUHlgJtgAxgDtAthLAon/P7AM1CCD32Ol4VWAbUDiH8nN/zpaamhvT09P3GJCIiezKzuSGE1Lzui6V00xxYFkJYHkLYAYwBOu/n/G7A6DyOdwHe3V+SFxGR4hdLoq8FrMx1OyP72D7M7ESgLvB+Hnd3Je9fAJhZTzNLN7P0devWxRCSiIjEKpZEb3kcy6/e0xUYF0LI2uMBzGoCjYEpeX1TCCEthJAaQkitXj3PEpOIiBRSLBdjM4Djc92uDazO59yuwB15HP8N8GYIYWfBwnM7d+4kIyODbdu2FebbBahYsSK1a9emQoUKUYciIqUslkQ/B6hnZnWBVXgyv3rvk8ysAVAFmJXHY3QDHihskBkZGRx++OHUqVMHs7w+YMj+hBBYv349GRkZ1K1bN+pwRKSUHbB0E0LIBHrjZZfFwNgQwhdm9piZdcp1ajdgTNhrGo+Z1cE/EcwobJDbtm3j6KOPVpIvJDPj6KOP1icikSQV0zz6EMIkYNJexx7a6/Yj+XzvCvK5eFsQSvJFo9dPJHnFlOhFRIrDtm3w7bfwzTewYgWsWQO7dkUdFdSsCddfD4cdFnUkJUOJXkSKzfbtsHLl7kSe85U7se+tLHzYDAEeeQTuvx9uuw0qVYo6ouKlRB+xQYMG0b9//wJ/380338zdd99Nw4YNSyAqkbzt3OmJPHfyzv331as9aeY46CA44QSoUwfat/c/69b1P+vU8ZF0+fKl/3PsbeZMT/T33ANPPQX9+sGtt8Khh0YdWfE4YAuE0pZXC4TFixdz6qmnRhRRyapcuTKbN2/e53gIgRAC5coVX9+5RH4dpXhkZkJGxr6JPOf2qlV7llrKlYPjj98zeedO5scd58k+Xnz0kSf899/3X0L9+kHPnlCxYtSRHdj+WiDE0T+Bu/NOmD+/eB+zaVN49tkDn3fZZZexcuVKtm3bRt++fenZsyeTJ0+mf//+ZGVlUa1aNaZNm8bmzZvp06cP6enpmBkPP/wwV1xxxT6P169fP7Zu3UrTpk1p1KgRjz/+OO3bt6dVq1bMmjWLt956i8GDBzNnzhy2bt1Kly5dePTRRwFo2bIlQ4YMITU1lcqVK9O3b18mTJjAoYceyttvv80xxxxTvC+SJIxt22DuXPj6632T+cqVkJVruWO5clCrlifuVq32TeS1akEiLc04/3yYNg1mzPCE37cvPPkkPPAA3HxzfCT8vMTdiD7KRP/DDz9QtWpVtm7dyplnnsm0adNITU3lww8/pG7dur/cf//997N9+3aezX7QDRs2UKVKlTwfM/eIfsWKFZx00kl88sknnH322Xs8Z1ZWFq1bt2bYsGGkpKTskejNjPHjx3PppZdy3333ccQRRzBgwIB9nksj+uS0fTvMng0ffADTp/vft2/3+8x81L13SSXn77Vrw8EHRxZ65KZPh4cf9pF+rVrQvz/cdBMcckjUke0roUb0sSTkkjJs2DDefPNNAFauXElaWhoXXHDBL4uQqlatCsDUqVMZM2bML9+XX5LPy4knnvhLkgcYO3YsaWlpZGZmsmbNGhYtWkRKSsoe33PwwQfTsWNHAM444wzee++9wv2AkhB27IB//9uT1AcfwCef+CjeDJo1g9694YILoGFDL7uUxaRVVrRqBS1beinn4Yfhjjtg8GBP+D16xM8vwbhL9FH54IMPmDp1KrNmzaJSpUq0bNmSJk2asGTJkn3ODSEUet76Ybnmd33zzTcMGTKEOXPmUKVKFbp3757noqcKFSr88nzly5cnMzOzUM8t8WnHDkhP353YZ86ErVs9sTdpArff7snqggvgqKOijjb+mEHr1nDRRTB1qif822+HJ56ABx+E7t3LfsLXDlMx2rRpE1WqVKFSpUp8+eWXzJ49m+3btzNjxgy++eYbwMssAG3btmX48OG/fO+GDRvyfdwKFSqwc2feLYB+/PFHDjvsMI488ki+++473n333WL8iSRe7dzp5ZcnnoBf/xqqVIEWLWDAAFi71i8evvkmfP89zJsHzzwDnTopyReVGbRp479IJ0/2i7W33gr168PIkf7vUlYp0ceoXbt2ZGZmkpKSwu9//3vOPvtsqlevTlpaGpdffjlNmjThqquuAmDAgAFs2LCB0047jSZNmjB9+vR8H7dnz56kpKRwzTXX7HNfkyZNaNasGY0aNaJHjx60aNGixH4+KbsyM70U8+STPkWxalU45xwvH6xe7TXj11/3xP7ZZ17evOwyP0+Kn5n/gp01CyZNgho14JZboEEDGDWqbCb8uLsYK4Wn1zE+ZGX5SDynFPPRR/DTT35fw4a768YXXgjq6h29EDzhP/KIl9BOOgl+/3u49trSnVqaUBdjRRJNVpaPxHMS+4cfwo8/+n2nnOIJIyexa9Zs2WMGHTrAJZfAhAme8G+8ER5/3BP+1VdHv5ZAib6UnHXWWWzPmdOW7eWXX6Zx48YRRSRR2bULPv98z8S+caPfV78+dOvmib1lSzj22AgDlQIxg0svhY4dYfx4T/g33AB/+AM89JD/u0a1CliJvpR8+umnUYeQtDIz4bHHoCz8E2Rmelkm5/r8ySfDlVfuTuzHHRdldFIczKBzZ78A/tZbnvCvu253wr/qqtJP+Er0ktC2bPGR1DvvwOmnRz8Nzgz+7/9219lr1442Hik5Of/WnTv7LKhHHoFrrtmd8K+8svQSvhK9JKy1a/2jdHo6jBgBvXpFHZEko3Ll4IorPOm//jo8+qgPPgYO9Dn5Xbr4OSUaQ8k+vEg0vvoKzj0XFiyAN95QkpfolSvno/jPP4cxY3y2zlVX+aK2ceNKti+/En3EBg0aVOjvfemll1i9Or992pPX7Nme5Ddt8qXrnTtHHZHIbuXKeYJfsABefdWv21x5pbeneOONPds8F9tzFv9DSkEo0Revt9/2pepHHuk9XnK1DRIpU8qX9xLOwoXwj394P6KhQ0vmuZToC+Cyyy7jjDPOoFGjRqSlpQEwefJkTj/9dJo0aULr1q0B2Lx5MzfeeCONGzcmJSWF119/Pc/Hy92mOGdl7D/+8Q+aN29O06ZNufXWW8nKyiIrK4vu3btz2mmn0bhxY4YOHcq4ceNIT0/nmmuuoWnTpmzdurV0XoQybMQIuPxyaNzYk3y9elFHJHJg5cv7RdovvoCxY0tmx634uxgbYZ/iUaNG7dGmuHPnztxyyy17tCkGGDhwIEceeSQLFiwA8u91M3jwYIYPH8787J9n8eLFvPbaa8ycOZMKFSrQq1cvXnnlFRo1asSqVatYuHAhABs3buSoo45i+PDhv7QqTma7dnk7gCef9IuvY8Yk3lZwkvgOOsj755TIY5fMwyamkm5TPG3aNObOncuZZ54JwNatW6lRowaXXnopy5cvp0+fPnTo0IG2bdsW548V17Zv93axr77qHQWHDYt+FaJIWRN//yUiakhfGm2KQwjccMMNPPHEE/vc99lnnzFlyhRGjBjB2LFjGTVqVKF+jkSycaOXaqZP906O999fNjaaFilrVKOPUWm0KW7dujXjxo1j7dq1vzzef//7X77//nt27drFFVdcwcCBA/nPf/4DwOGHH85POd2ukszKlXDeefDxx34hq18/JXmR/CjRx6g02hQ3bNiQP/zhD7Rt25aUlBTatGnDmjVrWLVqFS1btqRp06Z07979lxF/9+7due2225LuYuznn/tsmpUrvS94Hh2eRSQXtSlOIonwOk6b5isMjzgC3n3XZ9iIyP7bFGtEL3Hj5ZehXTvftHr2bCV5kVjF38XYOKU2xYUXwu79OS+6yFcPHnlk1FGJxA8l+lKiNsWFk5kJvXvDCy94LX7UqOg7UIrEm7gp3ZS1awnxJh5fvy1bvB7/wgvwwANeulGSFym4uBjRV6xYkfXr13P00UcXan56sgshsH79eipWrBh1KDH77jtf5Tp3Ljz/PNx2W9QRicSvuEj0tWvXJiMjg3Xr1kUdStyqWLEiteNkl4ulS6F9e1izxnfoufTSqCMSiW9xkegrVKjwS5sBSWyzZnliL1fO91Nt3jzqiETiX9zU6CXxvfWWz6qpUsW7TyrJixQPJXopE4YP9741TZt6kj/55KgjEkkcSvQSqV274L77oE8f6NTJV75Wrx51VCKJJS5q9JKYtm+H7t29f3yvXt5iuHz5qKMSSTxK9BKJDRt8jvyMGb5hyO9+p+6TIiVFiV5K3bff+vTJr77yDUO6dYs6IpHEFlON3szamdkSM1tmZv3yuH+omc3P/lpqZhtz3XeCmf3LzBab2SIzq1N84Uu8mT/fWwyvWgVTpijJi5SGA47ozaw8MAJoA2QAc8xsfAhhUc45IYS7cp3fB2iW6yH+DjweQnjPzCoDu4oreIkv770HV1zhDck+/hhOOy3qiESSQywj+ubAshDC8hDCDmAM0Hk/53cDRgOYWUPgoBDCewAhhM0hhJ+LGLPEob/9DS65BOrW9RbDSvIipSeWRF8LWJnrdkb2sX2Y2YlAXeD97EP1gY1m9oaZzTOzp7M/Iez9fT3NLN3M0tXmILGEAH/4g8+uadkSPvoIauX57hGRkhLLxdi85kLk1wqxKzAuhJCV6/HPx0s53wKvAd2Bv+7xYCGkAWngO0zFEFOZlZ4O110HmzZFHUnZkJUFa9f6azJypLpPikQhlkSfARyf63ZtYHU+53YF7tjre+eFEJYDmNlbwNnslegTxU8/QdeusHUrdOwYdTRlR0oK3HGHpk+KRCWWRD8HqGdmdYFVeDK/eu+TzKwBUAWYtdf3VjGz6iGEdcBFQPre35soeveGb77xueHnnRd1NCIi7oA1+hBCJtAbmAIsBsaGEL4ws8fMrFOuU7sBY0KuHS6ySzj3AtPMbAFeBvp/xfkDlBWvvgp//zv8/vdK8iJStlhZ23koNTU1pKfH16B/+XJvxpWS4q11D9IyNBEpZWY2N4SQmtd9ampWRDt3wtVXe//0V15RkheRskdpqYgefRQ+/RReew1OPDHqaERE9qURfRF88AEMGgQ9esBvfhN1NCIieVOiL6T16+Haa6FePXjuuaijERHJn0o3hRAC3HKLLwSaPRsqV446IhGR/CnRF0JaGrz5JgwZAqefHnU0IiL7p9JNAS1aBHfdBW3b+p8iImWdEn0BbNvm/dMrV/ZujOX06olIHFDppgDuvx8+/xwmToRjj406GhGR2GhMGqOJE33z6r59va+6iEi8UKKPwZo13k+9SRPfyFpEJJ6odHMAu3bBDTfAli0wejQcckjUEUncWr/e91L86quoIyk7Dj0UWrXyvt6tW2uucglRoj+AZ57xvU5feAFOPTXqaCRubd8Ol1/u/TKuuUZX8nOsXw9jx+7elaZlS+jQwb9+9auoo0sY6l65H3PnwjnnwKWXwrhx2jhDCikEuPFGn6r16qs+dUt227EDZs6ECRP8YtiSJX78lFN2J/3zzoMKFaKNs4zbX/dKJfp8bN7si6G2boXPPoOqVaOOSOLWoEHw4IPeAe+hh6KOpuz7+mtP+BMnekOpHTvgiCN88UrHjtC+PdSoEXWUZY4SfSH06AEvvQTTp8OFF0YdjcStsWPhqqu8MdLf/66PhQW1eTNMm+aj/UmTYPVqfw3PPHP3aL9ZM5XCUKIvsNde871fBwyAgQMjDUXi2ezZXnM+80yYOlVX8osqBJg/f/do/9NP/VjNmj7nuUMHuPhiOPzwqCONhBJ9AaxY4dMoGzWCDz/URiJSSCtWwFln+SySTz+FatWijijxrFsH777rSX/KFNi0yev4F17oJZ4OHeDkk6OOstQo0ccoM9PfIwsX+sChbt1IwpB4t2kTtGgBq1bBrFl+UVFK1s6d8MknnvQnTIDFi/14/fq7Szznn+8zexKUthKM0cCB/l75y1+U5KWQMjN9F5olS+D115XkS0vOSP6pp7zz4PLl8Kc/wUknwZ//7CWdatWgSxd48UX43/+ijrhUaUSf7aOPvJx63XV+EVakwEKAXr18pDByJNx0U9QRCfhqx2nTdtf2V63y46mpPtLv2NGn2MX5BV2Vbg5gwwavyx9yCPznP0l7LUeK6tlnvXf1/ffD4MFRRyN5CWF3Z8IJE/yCeQhQpw48/bSvXI7TmVEq3exHCNCzp/ezGT1aSV4K6Z134O67ffXroEFRRyP5MfNRXf/+XqdduxZefhmOPBKuvNJLPAsXRh1lsUv6RP/Xv/qq18cf909yIgU2f76vdj3jDE8acV4CSCrVqvkah/R0r+XPnw9Nm3qb2g0boo6u2CT1O/LLL/3f8+KL4d57o45G4tLq1V7jrVIFxo+HSpWijkgK46CD4PbbYelS/4g/fLjP2Bk5ErKyoo6uyJI20W/f7oOwSpV8waIGYVJgW7Z4I6RNm7zeW7Nm1BFJUR19tI/s09N9xtQtt/h6iFmzoo6sSJI2vT3wgH9Ke/FF/f+UQsjK8i6U8+fDmDFe95XE0ayZr5h89VW/gHfuud6vfM2aqCMrlKRM9JMnw9Ch0Lu3f+oWKbB+/eDtt32mTYcOUUcjJcHMP/YvWeIjwzFjoEEDGDLEG63FkaRL9N9957+YGzf22VQiBZaW5v/Ze/eGPn2ijkZKWuXKPpPqiy98UdbvfucJZPLkqCOLWVIl+l27fEvAH3/0qZQVK0YdkcSdqVN9UVT79v6xUJLHySf7NNqJE31edvv20Lmzt1Uu45Iq0T/3nP8SfuYZb1omUiCLFvkS+oYN/WO8Ot4lp0sugQULfAPp99/3ZDJggF+cL6OSJtHPm+cLFi+7DG67LepoJO6sXesXdCpW9Bk2RxwRdUQSpUMOgfvu8/r9lVf6QpxTTvEBQBnrNgBJkui3bPFrKjVq+LTYOF3hLFHZts1HCGvW+Fz5E06IOiIpK447zhfJffwxVK/uiaZlS9+WrgxJikR/552+DuLll32arEjMQvDtxmbN8jdQ8+ZRRyRlUYsWMGcOvPCCX7Q9/XS44w744YeoIwOSINGPG+ej+H79oFWrqKORuPPoo37l/oknvD4vkp/y5X1V7dKlu7uY1q/vyT/i1bUJnei//Xb3wrZHH406Gok7r7zib5wbb/QLPCKxqFrVe+HPmwenneYXBVNTvbwTkYRN9DkLF7OyfHFbhQpRRyRx5eOPvWTTsqWPzHRhRwoqJQWmT/dNqL//3ne4uvba3f3wS1HCJvrHH/f/q88/75vMiMTs66/94mudOr5LVAJvPyclzMx3HPvyS5+COW6cr64dPNgbbpWShEz0M2f6J+5rr/VRvUjMNmzwlgYh+MKYqlWjjkgSwWGH+V6lixZ5u9wHHvCyzsSJpfL0MSV6M2tnZkvMbJmZ9cvj/qFmNj/7a6mZbcx1X1au+8YXZ/B52bgRrr7aB2MjRpT0s0lC2bHDdxhavhzeestXQooUp5NO8vfW5Ml+8bZjR//66qsSfdoDJnozKw+MANoDDYFuZtYw9zkhhLtCCE1DCE2BPwFv5Lp7a859IYROxRj7PkKAW2/1FuGjR2tNixRAzn6v06f7NK3zz486Iklkv/61b2k4ZIh3yWzUyKcGbt5cIk8Xy4i+ObAshLA8hLADGAN03s/53YDRxRFcQb30Eowd65+QNN1ZCuTpp327sQED4Prro45GksHBB8M99/h0zKuv9pYKLVqUyMraWBJ9LWBlrtsZ2cf2YWYnAnWB93Mdrmhm6WY228wuy+f7emafk75u3boYQ9/T1197I8FWrby5nEjM3njDp09edZXm4UrpO/ZYH6XOmuXvvxKY4RVLV6a8njW/XzldgXEhhNyrA04IIaw2s5OA981sQQhhj3ZvIYQ0IA0gNTW1UL/OTjjBE/zNN3vpSyQm6el+1f7ss30XGm01JlE5++wSe+hY3tUZwPG5btcGVudzblf2KtuEEFZn/7kc+ABoVuAoY1ChAjz8MNTK87OGSB5WrvStAI85xi+QHXpo1BGJlIhYEv0coJ6Z1TWzg/Fkvs/sGTNrAFQBZuU6VsXMDsn+ezWgBbCoOAIXKZKffvLZDj//7N0ojzkm6ohESswBSzchhEwz6w1MAcoDo0IIX5jZY0B6CCEn6XcDxoSwx5WEU4EXzGwX/ktlcAhBiV6ilZkJXbt686lJk7Q5gSS8mHZOCCFMAibtdeyhvW4/ksf3fQI0LkJ8IsXvnns8wf/lL9C2bdTRiJQ4XXmS5DJ8OAwbBnff7YsuRJKAEr0kj0mToG9f6NQJnnoq6mhESo0SvSSHzz7zefIpKd5+WHNwJYlod2NJTCF4cp840WfVfPop1KwJ77wDlStHHZ1IqVKil8SxZQtMnerJfdKk3X2/U1PhoYege3eoXTvSEEWioEQv8W35ck/sEyd6Q7IdO+Dww6FNG58n3769LzEXSWJK9BJfdu70DQdySjJffunH69f3zZg7dPDOk9osROQXSvRS9q1dC+++68n9X/+CTZu858WFF/oUyQ4doF69qKMUKbOU6KXsCcE3Vs4pyfz7337s2GOhSxdP7Bdf7CUaETkgJXopGzZv9gupEyb4hdQ1a7xd65lnwiOPeHJv1kzdJUUKQYleorNs2e5R+4wZfiH1iCO8LUHOhdQaNaKOUiTuKdFL6dmxAz7+eHdyX7LEj59yiu8a06EDnHee199FpNgo0UvJ2rjRe71PmOAXUn/6yWfEtGzpe7R26AC/+lXUUYokNCV6KRlZWb4Ha//+sH49HHectwbu0AFat9bqVJFSpEQvxW/mTC/FzJsHF1zgmx6fdVaJ7IUpIgemKQxSfFavhuuu8zr7unUwZgx88IHvhakkLxIZJXopuu3bve1vgwYwdiw8+KCvWL3qKiV4kTJApRspmnff9R7vX33lfd6feUYXV0XKGI3opXCWLYNLL4VLLvFR+7vvwttvK8mLlEFK9FIwmzfDAw/4htoffABPPw0LFkC7dlFHJiL5UOlGYhMCjB4Nv/udX3S9/noYPNg38xCRMk0jejmw+fN9muQ113hi/+QT+NvflORF4oQSveRv/XpfvXrGGd6uYORI7yR5zjlRRyYiBaBEL/vKyoI//9l7vKelQe/esHQp3HSTukeKxCHV6GVPH34Iv/2tb6zdqhUMGwannRZ1VCJSBBqeicvIgG7dfNemDRvgn/+EadOU5EUSgBJ9stu2DQYN8lWtb70FDz8Mixf7Tk5a1SqSEFS6SVYheOvgO++E5cvh8svhj3+EOnWijkxEiplG9MloyRJf0dqpExxyCLz3Hrz+upK8SIJSok8mP/4I990HjRv7XPihQ/2i68UXRx2ZiJQglW6Swa5d8MornuT/9z/o0cPr8sccE3VkIlIKlOgT3dy5vgnIrFnQvLk3HmvePOqoRKQUqXSTqNatg5494cwz4euv4cUXdyd7EUkqSvSJJjPTFznVq+fJ/a67fFVr9+5a1SqSpFS6SSTTp/uq1oULoU0beO45OPXUqKMSkYhpiJcIvv0WfvMbuOgi7xf/5pswZYqSvIgAGtHHt61bfeOPwYP99mOPwb33wqGHRhuXiJQpSvTxKARvV3D33bBihY/mn34aTjgh6shEpAyKqXRjZu3MbImZLTOzfnncP9TM5md/LTWzjXvdf4SZrTKz4cUVeNJavBjatvWWBZUrw/vvw2uvKcmLSL4OOKI3s/LACKANkAHMMbPxIYRFOeeEEO7KdX4foNleDzMQmFEsESerTZvg0UfhT3/yBD9sGNx+OxykD2Uisn+xjOibA8tCCMtDCDuAMUDn/ZzfDRidc8PMzgCOAf5VlECT1q5dPk2yfn149llf1bp0qS+CUpIXkRjEkuhrAStz3c7IPrYPMzsRqAu8n327HPBH4Hf7ewIz62lm6WaWvm7duljiTg452/b16AG/+hXMmQMvvADVq0cdmYjEkVgSfV5NyUM+53YFxoUQsrJv9wImhRBW5nO+P1gIaSGE1BBCanUlMfjuO0/uZ50FK1fCyy/DzJm+d6uISAHF8tk/Azg+1+3awOp8zu0K3JHr9jnA+WbWC6gMHGxmm0MI+1zQFWDnThg+HB55xKdO3ncfDBgAhx8edWQiEsdiSfRzgHpmVhdYhSfzq/c+ycwaAFWAWTnHQgjX5Lq/O5CqJJ+PqVN9VevixdCundfjGzSIOioRSQAHLN2EEDKB3sAUYDEwNoTwhZk9Zmadcp3aDRgTQsivrCN5+eYbnyrZpg1s3w7jx8OkSUryIlJsrKzl5dTU1JCenh51GCXv55/hySfhqae82diAAd6ArGLFqCMTkThkZnNDCKl53af5eaUtBN+27557vEdNt26e7GvXjjoyEUlQampWmhYu9G37rrwSqlSBDz+EV19VkheREqVEXxo2bIC+faFpU5g/H/78Z0hPh/PPjzoyEUkCKt2UpKwsX9X6wAPwww9w660wcCAcfXTUkYlIEtGIvqTMmuULnm65xfvCz53rI3kleREpZUr0xW3LFrjhBjj3XFizxmvwM2Z42UZEJAJK9MXtnnu8ZUG/frBkic+qsby6SIiIlA7V6IvTlCnedOzee+GJJ6KORkQE0Ii++GzYADfdBA0b+gVXEZEyQiP64vLb38L//gdvv63VrSJSpmhEXxzeeAP+8Q9vY6BWwiJSxijRF9XatXDbbXD66fDgg1FHIyKyD5VuiiIET/KbNsH06VChQtQRiYjsQ4m+KF55Bd5804dtLr8AAAisSURBVJuSNWoUdTQiInlS6aawMjKgd29o0QLuvjvqaERE8qVEXxghwM03+9Z/L70E5ctHHZGISL5UuimMtDRfHDViBJx8ctTRiIjsl0b0BbV8ubc5uPhivxArIlLGKdEXRFYWdO/upZpRo3wLQBGRMk6lm4J47jn46COvyx9/fNTRiIjEREPSWC1eDP37Q6dOcP31UUcjIhIzJfpY7Nzpyb1yZb8Qq7bDIhJHVLqJxeDBvsfrP/8JxxwTdTQiIgWiEf2BzJsHjz3mG4h06RJ1NCIiBaZEvz/bt3vJpnp1GD486mhERApFpZv9efhhWLgQJk6EqlWjjkZEpFA0os/PJ5/A0097q4NLLok6GhGRQlOiz8uWLXDDDXDCCfDMM1FHIyJSJCrd5KVfP1i2zHvMH3541NGIiBSJRvR7mzbNL7z27QstW0YdjYhIkSnR57ZpE9x4I9SvD4MGRR2NiEixUOkmt7vuglWr/EJspUpRRyMiUiw0os/xzjvw4otenz/rrKijEREpNkr0AN9/D7fcAikp8NBDUUcjIlKsVLoBuOMO+OEH3zXqkEOijkZEpFgp0b/2GowdC48/Dk2aRB2NiEixS+7SzZo10KuX1+Tvuy/qaERESkTyJvoQvC7/88/wt7/BQfpwIyKJKXmz24sverOyZ5+FBg2ijkZEpMTENKI3s3ZmtsTMlplZvzzuH2pm87O/lprZxuzjJ5rZ3OzjX5jZbcX9AxTKihVw552+8rVPn6ijEREpUQcc0ZtZeWAE0AbIAOaY2fgQwqKcc0IId+U6vw/QLPvmGuDcEMJ2M6sMLMz+3tXF+UMUyK5d0KOHl25efBHKJW/1SkSSQyxZrjmwLISwPISwAxgDdN7P+d2A0QAhhB0hhO3Zxw+J8flK1ogR3qxs6FCoUyfqaERESlwsibcWsDLX7YzsY/swsxOBusD7uY4db2afZz/Gk3mN5s2sp5mlm1n6unXrChJ/wSxdCvffD+3bw003ldzziIiUIbEkesvjWMjn3K7AuBBC1i8nhrAyhJACnAzcYGb77K4dQkgLIaSGEFKrV68eS9wFl5npPeYrVoSRI8Hy+rFERBJPLIk+Azg+1+3aQH419q5kl232lj2S/wI4vyABFpshQ2D2bC/dHHdcJCGIiEQhlkQ/B6hnZnXN7GA8mY/f+yQzawBUAWblOlbbzA7N/nsVoAWwpDgCL5AFC7yHTZcu0LVrqT+9iEiUDjjrJoSQaWa9gSlAeWBUCOELM3sMSA8h5CT9bsCYEELuss6pwB/NLOAloCEhhAXF+yMcwI4dcN11UKUKPP+8SjYiknRiWjAVQpgETNrr2EN73X4kj+97D0gpQnxFN3AgfPYZvP02VKsWaSgiIlGIfrpjSfr3v+GJJ/wibKdOUUcjIhKJxE30W7d6gq9Z09sciIgkqcTtdfPgg/Dll/Dee3DUUVFHIyISmcQc0c+Y4aP4Xr3g4oujjkZEJFKJl+h/+gm6d4eTToKnnoo6GhGRyCVe6ebee+G//4WPPoLDDos6GhGRyCXWiH7yZEhL82TfokXU0YiIlAmJk+g3bPBGZY0awWOPRR2NiEiZkTiJfudOSE31bQErVow6GhGRMiNxavQ1avjqVxER2UPijOhFRCRPSvQiIglOiV5EJMEp0YuIJDglehGRBKdELyKS4JToRUQSnBK9iEiCsz23eI2ema0D/ht1HEVUDfg+6iDKEL0ee9LrsZteiz0V5fU4MYRQPa87ylyiTwRmlh5CSI06jrJCr8ee9HrsptdiTyX1eqh0IyKS4JToRUQSnBJ9yUiLOoAyRq/HnvR67KbXYk8l8nqoRi8ikuA0ohcRSXBK9CIiCU6JvojM7Hgzm25mi83sCzPrm328qpm9Z2ZfZf9ZJepYS4uZlTezeWY2Ift2XTP7NPu1eM3MDo46xtJiZkeZ2Tgz+zL7PXJOkr837sr+f7LQzEabWcVken+Y2SgzW2tmC3Mdy/P9YG6YmS0zs8/N7PTCPq8SfdFlAveEEE4FzgbuMLOGQD9gWgihHjAt+3ay6AssznX7SWBo9muxAbgpkqii8RwwOYRwCtAEf12S8r1hZrWA3wKpIYTTgPJAV5Lr/fES0G6vY/m9H9oD9bK/egLPF/pZQwj6KsYv4G2gDbAEqJl9rCawJOrYSunnr539Zr0ImAAYvtLvoOz7zwGmRB1nKb0WRwDfkD3pIdfxZH1v1AJWAlXxbUwnAL9OtvcHUAdYeKD3A/AC0C2v8wr6pRF9MTKzOkAz4FPgmBDCGoDsP2tEF1mpeha4D9iVfftoYGMIITP7dgb+Hz4ZnASsA17MLmWNNLPDSNL3RghhFTAE+BZYA2wC5pK8748c+b0fcn4x5ij0a6NEX0zMrDLwOnBnCOHHqOOJgpl1BNaGEObmPpzHqckyp/cg4HTg+RBCM2ALSVKmyUt27bkzUBc4DjgML0/sLVneHwdSbP93lOiLgZlVwJP8KyGEN7IPf2dmNbPvrwmsjSq+UtQC6GRmK4AxePnmWeAoMzso+5zawOpowit1GUBGCOHT7Nvj8MSfjO8NgIuBb0II60IIO4E3gHNJ3vdHjvzeDxnA8bnOK/Rro0RfRGZmwF+BxSGEZ3LdNR64IfvvN+C1+4QWQngghFA7hFAHv8j2fgjhGmA60CX7tKR4LQBCCP8DVppZg+xDrYFFJOF7I9u3wNlmVin7/03O65GU749c8ns/jAeuz559czawKafEU1BaGVtEZnYe8BGwgN116f54nX4scAL+Br8yhPBDJEFGwMxaAveGEDqa2Un4CL8qMA+4NoSwPcr4SouZNQVGAgcDy4Eb8QFWUr43zOxR4Cp8tto84Ga87pwU7w8zGw20xNsRfwc8DLxFHu+H7F+Gw/FZOj8DN4YQ0gv1vEr0IiKJTaUbEZEEp0QvIpLglOhFRBKcEr2ISIJTohcRSXBK9CIiCU6JXkQkwf1/Z6GYbJuMrlAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = [10,20, 30, 40, 50, 60,70,80,90,100]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=n_estimators[i])\n",
    "\n",
    "    # Train Adaboost Classifer\n",
    "    model = bdt.fit(X_train, y_train)\n",
    "    accuracy_train.append(bdt.score(X_train, y_train))\n",
    "    accuracy_test.append(bdt.score(X_test, y_test))\n",
    "\n",
    "\n",
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = [10,20, 30, 40, 50, 60,70,80,90,100]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5), algorithm=\"SAMME\", n_estimators=n_estimators[i])\n",
    "\n",
    "    # Train Adaboost Classifer\n",
    "    model = bdt.fit(X_train, y_train)\n",
    "    accuracy_train.append(bdt.score(X_train, y_train))\n",
    "    accuracy_test.append(bdt.score(X_test, y_test))\n",
    "\n",
    "\n",
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance des features selectionnées par AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure()\n",
    "    plt.barh(range(n_features),sorted(model.feature_importances_), align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns) \n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(\"Features importance\", fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importances(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[171,  46],\n",
       "       [ 54, 209]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Classification multiclasse\n",
    "\n",
    "## 1. Création de ymulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On repart du dataset initial afin d'attribuer les 3 nouvelles modalités à partir de quality\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :11]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur l'application de la valeur des modalités : \n",
    "\n",
    "- Inférieur à 5 : 0\n",
    "- Egale à 5 : 1\n",
    "- Supérieur à 5 : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implémentation de ymulti en fonction de la moyenne\n",
    "\n",
    "ymulti = []\n",
    "\n",
    "for i in y:\n",
    "    \n",
    "    if i < 5:\n",
    "        ymulti.append(0)\n",
    "        \n",
    "    elif i == 5:\n",
    "        ymulti.append(1)\n",
    "    else:\n",
    "        ymulti.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ymulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1=df.assign(ymulti= ymulti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>ymulti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  ymulti  \n",
       "0         9.4        5       1  \n",
       "1         9.8        5       1  \n",
       "2         9.8        5       1  \n",
       "3         9.8        6       2  \n",
       "4         9.4        5       1  \n",
       "...       ...      ...     ...  \n",
       "1594     10.5        5       1  \n",
       "1595     11.2        6       2  \n",
       "1596     11.0        6       2  \n",
       "1597     10.2        5       1  \n",
       "1598     11.0        6       2  \n",
       "\n",
       "[1599 rows x 13 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>ymulti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  ymulti  \n",
       "0         9.4       1  \n",
       "1         9.8       1  \n",
       "2         9.8       1  \n",
       "3         9.8       2  \n",
       "4         9.4       1  \n",
       "...       ...     ...  \n",
       "1594     10.5       1  \n",
       "1595     11.2       2  \n",
       "1596     11.0       2  \n",
       "1597     10.2       1  \n",
       "1598     11.0       2  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On cherche à prédire ymulti, on supprime quality\n",
    "new_df1.drop(\"quality\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df1.iloc[:, :11]\n",
    "y = new_df1.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre d'occurence par modalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    855\n",
       "1    681\n",
       "0     63\n",
       "Name: ymulti, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df1['ymulti'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    588\n",
       "1    486\n",
       "0     45\n",
       "Name: ymulti, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 588, 1: 588, 0: 588})\n"
     ]
    }
   ],
   "source": [
    "# Oversample and plot imbalanced dataset with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# transform the dataset\n",
    "oversample = SMOTE(random_state=0, sampling_strategy='all')\n",
    "X_train_balanced, y_train_balanced = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train_balanced)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train_balanced, y_train_balanced, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_val1, y_train2, y_val1 = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultats sur la base avec les données équilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.04890251159667969s\n",
      "inference time: 0.0030181407928466797s\n",
      "test score :  0.33584905660377357\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=1, early_stopping = True, max_iter=300,learning_rate_init=0.1)\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(X_train1, y_train1)\n",
    "stop = time.time()\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "start = time.time()\n",
    "test_score = clf.score(X_val, y_val)\n",
    "stop = time.time()\n",
    "print(f\"inference time: {stop - start}s\")\n",
    "print(\"test score : \", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'activation' : ['identity','logistic', 'tahn', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "              'learning_rate' : ['constant', 'invscaling', 'adaptive']\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gride = GridSearchCV(clf, param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.56644943 0.35419835 0.39379217 0.54611106 0.34521247 0.45138409\n",
      " 0.55268095 0.40924262 0.40520391 0.40366347 0.40601034 0.33549258\n",
      " 0.41160923 0.33306014 0.3945986  0.39298575 0.37274283 0.38821961\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.33954445 0.33063757 0.3314407\n",
      " 0.33873474 0.33549258 0.36059379 0.3662651  0.35735822 0.33549258]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=MLPClassifier(early_stopping=True, hidden_layer_sizes=1,\n",
       "                                     learning_rate_init=0.1, max_iter=300),\n",
       "             param_grid={'activation': ['identity', 'logistic', 'tahn', 'relu'],\n",
       "                         'learning_rate': ['constant', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'solver': ['lbfgs', 'sgd', 'adam']})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gride.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', early_stopping=True, hidden_layer_sizes=1,\n",
       "              learning_rate_init=0.1, max_iter=300, solver='lbfgs')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gride.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  gride.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.26685571670532227s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "model.fit(X_train1, y_train1)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference time: 0.003983259201049805s\n",
      "test score :  0.5509433962264151\n",
      "0.5786061588330632\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "test_score = model.score(X_val, y_val)\n",
    "stop = time.time()\n",
    "print(f\"inference time: {stop - start}s\")\n",
    "print(\"test score : \", test_score)\n",
    "print(model.score(X_train1, y_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[121,  23,  34],\n",
       "       [ 77,  59,  47],\n",
       "       [ 24,  33, 112]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 1, 0, 2, 2, 0, 1, 2, 1, 2,\n",
       "       1, 1, 2, 0, 2, 2, 1, 0, 2, 2, 2, 2, 1, 0, 0, 2, 2, 0, 0, 2, 0, 0,\n",
       "       0, 2, 0, 0, 0, 0, 1, 2, 2, 0, 0, 2, 0, 1, 0, 1, 0, 1, 2, 2, 1, 0,\n",
       "       2, 2, 2, 0, 0, 2, 1, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 0,\n",
       "       2, 2, 1, 1, 0, 2, 2, 2, 0, 2, 1, 2, 2, 0, 1, 2, 0, 2, 1, 0, 0, 2,\n",
       "       0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 1, 2, 2, 0, 2, 2, 0, 0,\n",
       "       1, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 2, 2, 1, 0, 1,\n",
       "       0, 2, 1, 0, 1, 1, 1, 1, 0, 0, 2, 1, 0, 0, 2, 0, 1, 2, 0, 2, 0, 0,\n",
       "       0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 0,\n",
       "       2, 2, 0, 0, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1,\n",
       "       2, 2, 2, 1, 0, 0, 0, 2, 0, 2, 1, 0, 1, 2, 1, 0, 2, 0, 0, 1, 0, 2,\n",
       "       0, 1, 2, 2, 1, 0, 2, 0, 1, 2, 0, 0, 0, 2, 0, 2, 2, 0, 1, 2, 1, 1,\n",
       "       0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 2, 2,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 0, 2, 1, 2, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0,\n",
       "       1, 0, 2, 1, 2, 1, 0, 1, 2, 0, 0, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2,\n",
       "       1, 0, 2, 0, 2, 1, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 0, 0,\n",
       "       1, 0, 2, 2, 2, 0, 1, 0, 2, 1, 2, 0, 1, 2, 0, 2, 0, 1, 0, 0, 2, 0,\n",
       "       2, 1, 1, 0, 0, 1, 2, 0, 2, 0, 2, 0, 0, 1, 2, 1, 2, 2, 2, 2, 0, 2,\n",
       "       2, 2, 1, 0, 2, 2, 1, 1, 0, 0, 2, 2, 0, 0, 2, 0, 1, 0, 1, 0, 2, 0,\n",
       "       0, 0, 0, 1, 0, 2, 2, 0, 1, 0, 2, 2, 2, 1, 0, 2, 0, 1, 1, 2, 2, 0,\n",
       "       2, 1, 0, 1, 1, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 1, 0, 2, 0, 0,\n",
       "       0, 1, 0, 1, 0, 2, 2, 2, 0, 0, 1, 2, 0, 2, 0, 2, 0, 0, 2, 1, 2, 2,\n",
       "       0, 0, 2, 2, 1, 2, 2, 0, 1, 1, 0, 1, 1, 0, 2, 0, 1, 1, 2, 1, 0, 0,\n",
       "       2, 0, 0, 2, 0, 0, 0, 2, 1, 2, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1,\n",
       "       2, 0], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultats sur la base avec les données non-équilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.0329134464263916s\n",
      "inference time: 0.001992940902709961s\n",
      "test score :  0.5509433962264151\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=1, early_stopping = True, max_iter=300,learning_rate_init=0.1)\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(X_train2, y_train2)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "start = time.time()\n",
    "test_score = model.score(X_val, y_val)\n",
    "stop = time.time()\n",
    "print(f\"inference time: {stop - start}s\")\n",
    "print(\"test score : \", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'tahn' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.68709783 0.50568349 0.6156051  0.6755757  0.55428711 0.56705047\n",
      " 0.67426915 0.52107627 0.61681365 0.56693614 0.5403152  0.54782786\n",
      " 0.592618   0.52235016 0.51458435 0.52235016 0.53508901 0.53517067\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.63719582 0.52235016 0.5274457\n",
      " 0.52235016 0.52235016 0.53390495 0.52235016 0.52235016 0.55427895]\n",
      "  category=UserWarning\n",
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {'activation' : ['identity','logistic', 'tahn', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "              'learning_rate' : ['constant', 'invscaling', 'adaptive']\n",
    "             }\n",
    "\n",
    "gride = GridSearchCV(clf, param_grid, cv = 5)\n",
    "\n",
    "gride.fit(X_train2, y_train2)\n",
    "\n",
    "model =  gride.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.1484360694885254s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudyl\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(X_train2, y_train2)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference time: 0.002959012985229492s\n",
      "test score :  0.7142857142857143\n",
      "0.719029374201788\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "test_score = model.score(X_val1, y_val1)\n",
    "stop = time.time()\n",
    "print(f\"inference time: {stop - start}s\")\n",
    "print(\"test score : \", test_score)\n",
    "print(model.score(X_train2, y_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model.predict(X_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   6,   2],\n",
       "       [  0,  96,  53],\n",
       "       [  0,  35, 144]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    179\n",
       "1    149\n",
       "0      8\n",
       "Name: ymulti, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "### Données équilibrées "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "n_estimators = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300,400,500,600,700,800,900, 1000]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    bagging = BaggingClassifier(base_estimator=MLPClassifier(early_stopping=True, hidden_layer_sizes=1))\n",
    "    model = bagging.fit(X_train1, y_train1)\n",
    "    accuracy_train.append(bagging.score(X_train1, y_train1))\n",
    "    accuracy_test.append(bagging.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données non-équilibrées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "n_estimators = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    bagging = BaggingClassifier(base_estimator=MLPClassifier(hidden_layer_sizes=1, early_stopping = True, max_iter=300,learning_rate_init=0.1))\n",
    "    model = bagging.fit(X_train2, y_train2)\n",
    "    accuracy_train.append(bagging.score(X_train1, y_train1))\n",
    "    accuracy_test.append(bagging.score(X_val1, y_val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 \n",
    "\n",
    "## Entrainement de forêt aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"max_depth\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "    \"n_estimators\": [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(clf, param_dist) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données équilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20],\n",
       "                                        'n_estimators': [25, 50, 75, 100, 125,\n",
       "                                                         150, 175, 200, 225,\n",
       "                                                         250, 275, 300]})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=19, n_estimators=250)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.6383697986602783s\n",
      "inference time: 0.03886246681213379s\n",
      "test score :  0.8037735849056604\n",
      "train: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train1, y_train1)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "start = time.time()\n",
    "test_score = model.score(X_val,y_val)\n",
    "stop = time.time()\n",
    "print(f\"inference time: {stop - start}s\")\n",
    "print(\"test score : \", test_score)\n",
    "print(\"train:\", model.score(X_train1, y_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    model1 = model.fit(X_train1, y_train1)\n",
    "    accuracy_train.append(model.score(X_train1, y_train1))\n",
    "    accuracy_test.append(model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5wU1Z338c9XBJH7bTSuo0Ky7CrIRWmVXbNKJCoQIygxXldRN0Sz+piYxHhLNCjqZn2SPD4as5gQ1BiVaIwkMbKKkOxm0dDIXTKKqGEAdRTvAjLDb/+oGmiHGaaBmWlm6vt+vfrV1adOnT6nq7t+Vaeq+igiMDOz7Nmj1BUwM7PScAAwM8soBwAzs4xyADAzyygHADOzjNqz1BXYEX369Im+ffuWuhpmZq3K/Pnz34iIsrrprSoA9O3bl3w+X+pqmJm1KpJeqS/dXUBmZhnlAGBmllEOAGZmGdWqzgHUZ9OmTVRWVrJhw4ZSV6VV6tixI+Xl5bRv377UVTGzFtbqA0BlZSVdu3alb9++SCp1dVqViODNN9+ksrKSfv36lbo6ZtbCiuoCkjRV0uuSljYwX5Juk7RC0mJJhxfMO0/SC+njvIL0YZKWpMvcpp3cem/YsIHevXt7478TJNG7d28fPZllVLHnAKYBo7YzfzTQP31MBO4EkNQLuA44CjgSuE5Sz3SZO9O8tcttr/zt8sZ/5/mzM8uuorqAIuKPkvpuJ8tY4J5I/lv6aUk9JO0HjACeiIh1AJKeAEZJmgN0i4i5afo9wDjg9zvZju36619h/frmKLltePVVuPjiUtfCzBoydCj88IdNX25TXQW0P7Cq4HVlmra99Mp60rchaaKkvKR8VVVVE1XXzMya6iRwff0IsRPp2yZGTAGmAORyuZ0avebAA3dmqdK66aabuPrqq3d4uX/5l3/h8ssvZ8CAAUUvs3kzzJmzw29lZq1cUx0BVAIHFLwuB9Y0kl5eT7qlbrrppnrTI4LNmzc3uNxPfvKTHdr4m1l2NdURwAzgEkkPkJzwfSci1kqaCdxUcOL3BOCqiFgn6T1Jw4FngHOB/7+rlfjqV2Hhwl0t5eOK6XsbN24cq1atYsOGDVx22WVMnDiRxx9/nKuvvpqamhr69OnDrFmzeP/997n00kvJ5/NI4rrrrmP8+PHblHfllVeyfv16hg4dysCBA5k8eTKjR4/mM5/5DHPnzuXXv/41t9xyC/PmzWP9+vV84Qtf4Lvf/S4AI0aM4NZbbyWXy9GlSxcuu+wyfvvb37L33nvz6KOPsu+++zbtB2RmrVZRAUDS/SQndPtIqiS5sqc9QET8GHgMGAOsAD4Ezk/nrZN0AzAvLWpS7Qlh4GKSq4v2Jjn52ywngFvC1KlT6dWrF+vXr+eII45g7NixfOlLX+KPf/wj/fr1Y926pMk33HAD3bt3Z8mSJQC89dZb9ZZ3yy23cPvtt7MwjWYvv/wyFRUV/OxnP+NHP/oRAJMnT6ZXr17U1NQwcuRIFi9ezODBgz9WzgcffMDw4cOZPHkyV1xxBXfddRfXXnttc30MZtbKFHsV0JmNzA/gXxuYNxWYWk96Hji0mPcvVnOcJS/GbbfdxiOPPALAqlWrmDJlCsccc8yWm6t69eoFwJNPPskDDzywZbmePXtuW1gDDjroIIYPH77l9fTp05kyZQrV1dWsXbuW5557bpsA0KFDB0466SQAhg0bxhNPPLFzDTSzNqnV3wlcanPmzOHJJ59k7ty5dOrUiREjRjBkyBAqKiq2yRsRO33dfefOnbdMv/TSS9x6663MmzePnj17MmHChHpv5mrfvv2W92vXrh3V1dU79d5m1jb5z+B20TvvvEPPnj3p1KkTf/nLX3j66afZuHEjf/jDH3jppZcAtnQBnXDCCdx+++1blm2oCwiSjfemTZvqnffuu+/SuXNnunfvzmuvvcbvf99qe8/MrIQcAHbRqFGjqK6uZvDgwXz7299m+PDhlJWVMWXKFE499VSGDBnC6aefDsC1117LW2+9xaGHHsqQIUOYPXt2g+VOnDiRwYMHc/bZZ28zb8iQIRx22GEMHDiQCy64gKOPPrrZ2mdmbZeS7vvWIZfLRd0RwZYvX84hhxxSohq1Df4Mzdo2SfMjIlc33UcAZmYZ5ZPAJXbUUUexcePGj6Xde++9DBo0qEQ1MrOscAAosWeeeabUVTCzjHIXkJlZRjkAmJlllAOAmVlGOQDsphr6N9BiTJs2jTVr/OeqZrZ9DgC7KQcAM2tuDgBNYNy4cQwbNoyBAwcyZcoUAB5//HEOP/xwhgwZwsiRIwF4//33Of/88xk0aBCDBw/m4Ycfrre8wr+Drr0T+Oc//zlHHnkkQ4cO5ctf/jI1NTXU1NQwYcIEDj30UAYNGsQPfvADHnroIfL5PGeffTZDhw5lvcfCNLMGtK3LQEs0IEBz/x308uXLefDBB/nTn/5E+/bt+cpXvsJ9993HwIEDWb16NUuXLgXg7bffpkePHtx+++1bxgQwM2tI2woAJdLcfwc9a9Ys5s+fzxFHHAHA+vXr2Wefffj85z/PypUrufTSS/nc5z7HCSec0JTNMrM2rm0FgBIMCNASfwcdEZx33nncfPPN28xbtGgRM2fO5I477mD69OlMnbrN0AtmZvUq6hyApFGSKiStkHRlPfMPkjRL0mJJcySVp+mfkbSw4LFB0rh03jRJLxXMG9q0TWsZLfF30CNHjuShhx7i9ddf31LeK6+8whtvvMHmzZsZP348N9xwA88++ywAXbt25b333muW9ppZ29FoAJDUDrgDGA0MAM6UVHfU8VuBeyJiMDAJuBkgImZHxNCIGAocRzJc5H8WLPfN2vkR0cSd9y2jJf4OesCAAdx4442ccMIJDB48mOOPP561a9eyevVqRowYwdChQ5kwYcKWI4QJEyZw0UUX+SSwmW1Xo38HLekfgOsj4sT09VUAEXFzQZ5lwIkRUamkj+OdiOhWp5yJwLERcXb6ehrw24h4qNjK+u+gm4c/Q7O2bVf+Dnp/YFXB68o0rdAiYHw6fQrQVVLvOnnOAO6vkzY57Tb6gaS9Gqj4REl5SfmqqqoiqmtmZsUoJgDUd9ay7mHDN4BjJS0AjgVWA1sGoJW0HzAImFmwzFXAwcARQC/gW/W9eURMiYhcROTKysqKqG7rctRRRzF06NCPPWovEzUza07FXAVUCRxQ8Loc+NhtphGxBjgVQFIXYHxEvFOQ5YvAIxGxqWCZtenkRkk/IwkimeO/gzazUinmCGAe0F9SP0kdSLpyZhRmkNRHUm1ZVwF1r0U8kzrdP+lRAek5g3HA0h2vfqI1DWu5u/FnZ5ZdjQaAiKgGLiHpvlkOTI+IZZImSTo5zTYCqJD0PLAvMLl2eUl9SY4g/lCn6PskLQGWAH2AG3emAR07duTNN9/0hmwnRARvvvkmHTt2LHVVzKwEWv2g8Js2baKyspINGzaUqFatW8eOHSkvL6d9+/alroqZNZOGrgJq9XcCt2/ffstfLpiZWfH8b6BmZhnlAGBmllEOAGZmGeUAYGaWUQ4AZmYZ5QBgZpZRDgBmZhnlAGBmllEOAGZmGeUAYGaWUQ4AZmYZ5QBgZpZRDgBmZhnlAGBmllEOAGZmGVVUAJA0SlKFpBWSrqxn/kGSZklaLGmOpPKCeTWSFqaPGQXp/SQ9I+kFSQ+mw02amVkLaTQASGoH3AGMBgYAZ0oaUCfbrcA9ETEYmATcXDBvfUQMTR8nF6T/G/CDiOgPvAVcuAvtMDOzHVTMEcCRwIqIWBkRHwEPAGPr5BkAzEqnZ9cz/2PSgeCPAx5Kk+4mGRjezMxaSDEBYH9gVcHryjSt0CJgfDp9CtBVUu/0dUdJeUlPS6rdyPcG3k4HnG+oTAAkTUyXz1dVVRVRXTMzK0YxAUD1pNUdSf4bwLGSFgDHAquB2o37gelgxGcBP5T0qSLLTBIjpkRELiJyZWVlRVTXzMyKUcyg8JXAAQWvy4E1hRkiYg1wKoCkLsD4iHinYB4RsVLSHOAw4GGgh6Q906OAbco0M7PmVcwRwDygf3rVTgfgDGBGYQZJfSTVlnUVMDVN7ylpr9o8wNHAcxERJOcKvpAucx7w6K42xszMitdoAEj30C8BZgLLgekRsUzSJEm1V/WMACokPQ/sC0xO0w8B8pIWkWzwb4mI59J53wIul7SC5JzAT5uoTWZmVgQlO+OtQy6Xi3w+X+pqmJm1KpLmp+diP8Z3ApuZZZQDgJlZRjkAmJlllAOAmVlGOQCYmWWUA4CZWUY5AJiZZZQDgJlZRjkAmJlllAOAmVlGOQCYmWWUA4CZWUY5AJiZZZQDgJlZRjkAmJlllAOAmVlGFRUAJI2SVCFphaQr65l/kKRZkhZLmiOpPE0fKmmupGXpvNMLlpkm6SVJC9PH0KZrlpmZNabRACCpHXAHMBoYAJwpaUCdbLcC90TEYGAScHOa/iFwbkQMBEYBP5TUo2C5b0bE0PSxcBfbYmZmO6CYI4AjgRURsTIiPgIeAMbWyTMAmJVOz66dHxHPR8QL6fQa4HWgrCkqbmZmu6aYALA/sKrgdWWaVmgRMD6dPgXoKql3YQZJRwIdgBcLkienXUM/kLRXfW8uaaKkvKR8VVVVEdU1M7NiFBMAVE9a3ZHkvwEcK2kBcCywGqjeUoC0H3AvcH5EbE6TrwIOBo4AegHfqu/NI2JKROQiIldW5oMHM7OmsmcReSqBAwpelwNrCjOk3TunAkjqAoyPiHfS192A3wHXRsTTBcusTSc3SvoZSRAxM7MWUswRwDygv6R+kjoAZwAzCjNI6iOptqyrgKlpegfgEZITxL+ss8x+6bOAccDSXWmImZntmEYDQERUA5cAM4HlwPSIWCZpkqST02wjgApJzwP7ApPT9C8CxwAT6rnc8z5JS4AlQB/gxqZqlJmZNU4Rdbvzd1+5XC7y+Xypq2Fm1qpImh8RubrpvhPYzCyjHADMzDLKAcDMLKMcAMzMMsoBwMwsoxwAzMwyygHAzCyjHADMzDLKAcDMLKMcAMzMMsoBwMwsoxwAzMwyygHAzCyjHADMzDLKAcDMLKMcAMzMMqqoACBplKQKSSskXVnP/IMkzZK0WNIcSeUF886T9EL6OK8gfZikJWmZt6VDQ5qZWQtpNABIagfcAYwGBgBnShpQJ9utJOP+DgYmATeny/YCrgOOAo4ErpPUM13mTmAi0D99jNrl1piZWdGKOQI4ElgRESsj4iPgAWBsnTwDgFnp9OyC+ScCT0TEuoh4C3gCGJUOCN8tIuZGMiblPSQDw5uZWQspJgDsD6wqeF2ZphVaBIxPp08BukrqvZ1l90+nt1cmAJImSspLyldVVRVRXTMzK0YxAaC+vvm6I8l/AzhW0gLgWGA1UL2dZYspM0mMmBIRuYjIlZWVFVFdMzMrxp5F5KkEDih4XQ6sKcwQEWuAUwEkdQHGR8Q7kiqBEXWWnZOWWV4n/WNlmplZ8yrmCGAe0F9SP0kdgDOAGYUZJPWRVFvWVcDUdHomcIKknunJ3xOAmRGxFnhP0vD06p9zgUeboD1mZlakRgNARFQDl5BszJcD0yNimaRJkk5Os40AKiQ9D+wLTE6XXQfcQBJE5gGT0jSAi4GfACuAF4HfN1WjzMyscUouwmkdcrlc5PP5UlfDzKxVkTQ/InJ1030nsJlZRjkAmJlllAOAmVlGOQCYmWWUA4CZWUY5AJiZZZQDgJlZRjkAmJlllAOAmVlGOQCYmWWUA4CZWUY5AJiZZZQDgJlZRjkAmJlllAOAmVlGOQCYmWVUUQFA0ihJFZJWSLqynvkHSpotaYGkxZLGpOlnS1pY8NgsaWg6b05aZu28fZq2aWZmtj2NDgovqR1wB3A8yWDu8yTNiIjnCrJdSzJU5J2SBgCPAX0j4j7gvrScQcCjEbGwYLmzI8JDfJmZlUAxRwBHAisiYmVEfAQ8AIytkyeAbul0d2BNPeWcCdy/sxU1M7OmVUwA2B9YVfC6Mk0rdD1wjqRKkr3/S+sp53S2DQA/S7t/vi1J9b25pImS8pLyVVVVRVTXzMyKUUwAqG/DXHck+TOBaRFRDowB7pW0pWxJRwEfRsTSgmXOjohBwD+lj3+u780jYkpE5CIiV1ZWVkR1zcysGMUEgErggILX5WzbxXMhMB0gIuYCHYE+BfPPoM7ef0SsTp/fA35B0tVkZmYtpJgAMA/oL6mfpA4kG/MZdfL8FRgJIOkQkgBQlb7eAziN5NwBadqekvqk0+2Bk4ClmJlZi2n0KqCIqJZ0CTATaAdMjYhlkiYB+YiYAXwduEvS10i6hyZERG030TFAZUSsLCh2L2BmuvFvBzwJ3NVkrTIzs0Zp63Z695fL5SKf91WjZmY7QtL8iMjVTfedwGZmGeUAYGaWUQ4AZmYZ5QBgZpZRDgBmZhnlAGBmllEOAGZmGeUAYGaWUQ4AZmYZ5QBgZpZRDgBmZhnlAGBmllEOAGZmGeUAYGaWUQ4AZmYZ5QBgZpZRRQUASaMkVUhaIenKeuYfKGm2pAWSFksak6b3lbRe0sL08eOCZYZJWpKWeZuk+gafNzOzZtJoAJDUDrgDGA0MAM6UNKBOtmuB6RFxGMmYwT8qmPdiRAxNHxcVpN8JTAT6p49RO98MMzPbUcUcARwJrIiIlRHxEcng7mPr5AmgWzrdHVizvQIl7Qd0i4i56djB9wDjdqjmZma2S4oJAPsDqwpeV6Zpha4HzpFUCTwGXFowr1/aNfQHSf9UUGZlI2UCIGmipLykfFVVVRHVNTOzYhQTAOrrm687kvyZwLSIKAfGAPdK2gNYCxyYdg1dDvxCUrciy0wSI6ZERC4icmVlZUVU18zMirFnEXkqgQMKXpezbRfPhaR9+BExV1JHoE9EvA5sTNPnS3oR+Lu0zPJGyjQzs2ZUzBHAPKC/pH6SOpCc5J1RJ89fgZEAkg4BOgJVksrSk8hI+iTJyd6VEbEWeE/S8PTqn3OBR5ukRWZmVpRGjwAiolrSJcBMoB0wNSKWSZoE5CNiBvB14C5JXyPpypkQESHpGGCSpGqgBrgoItalRV8MTAP2Bn6fPszMrIUouQindcjlcpHP50tdDTOzVkXS/IjI1U33ncBmZhnlAGBmllEOAGZmGeUAYGaWUQ4AZmYZ5QBgZpZRDgBmZhnlAGBmllEOAGZmGeUAYGaWUQ4AZmYZ5QBgZpZRDgBmZhnlAGBmllEOAGZmGeUAYGaWUUUFAEmjJFVIWiHpynrmHyhptqQFkhZLGpOmHy9pvqQl6fNxBcvMSctcmD72abpmmZlZYxodEjId0/cO4HiSwdznSZoREc8VZLsWmB4Rd0oaADwG9AXeAD4fEWskHUoyrOT+BcudHREe4svMrASKOQI4ElgRESsj4iPgAWBsnTwBdEunuwNrACJiQUSsSdOXAR0l7bXr1TYzs11VTADYH1hV8LqSj+/FA1wPnCOpkmTv/9J6yhkPLIiIjQVpP0u7f74tSfW9uaSJkvKS8lVVVUVU18zMilFMAKhvw1x3JPkzgWkRUQ6MAe6VtKVsSQOBfwO+XLDM2RExCPin9PHP9b15REyJiFxE5MrKyoqorpmZFaOYAFAJHFDwupy0i6fAhcB0gIiYC3QE+gBIKgceAc6NiBdrF4iI1enze8AvSLqazMyshRQTAOYB/SX1k9QBOAOYUSfPX4GRAJIOIQkAVZJ6AL8DroqIP9VmlrSnpNoA0R44CVi6q40xM7PiNRoAIqIauITkCp7lJFf7LJM0SdLJabavA1+StAi4H5gQEZEu97fAt+tc7rkXMFPSYmAhsBq4q6kbZ2ZmDVOynW4dcrlc5PO+atTMbEdImh8RubrpvhPYzCyjGr0RzKxFvfMOPPss5PMwbx4sXQrHHQff+Q7s45vFzZqSA4CVzgcfwIIFWzf2+Tw8//zW+f36wd/+Lfz4x3D33XDFFXD55dC5c+nqbNaGOABYy9iwARYtSjbytRv85cth8+Zkfnk55HJw7rnJcy4HvXsn8yoq4KqrkqOAH/0Irr8eLrwQ9vTX11rYm2/Cbbcl38POneGII7Z+X4cNgx49Sl3DHeKTwNb0Nm1Kum5q9+rzeViyBKqrk/llZckPp/bHM2wY7Ldf4+X+z/8kRwF/+hMcfDDcfDOMHQv130S++9u4EWpqoFOnUtfEGrN6NXz/+/Af/5EcuZ58MnTsmHy3V67cmq9//60BIZeDww+HLl1KV+9UQyeBHQBs19TUJHvyhd04ixYlGzeAnj23/hhqN/jl5Tu/0Y6ARx+FK69MjgyOPhr+/d/hH/6h6drU3Coqkg3JtGnw4YcwejScfjqcdNJusbGwAitWwPe+l3RB1tTAWWcl370BA7bmWbcO5s//+A7PqvTfcyQ45JCP/waGDIG9927RZjgAtFUffpicNK2paZn3i0j2hmo3+AsWJHUA6No12Zsv/LL369c8e+jV1TB1Klx3Hbz6KpxySnJE8Pd/3/Tv1RQ2bYJf/zo5n/HUU9C+PZx6Kuy7L/zyl7B2bbJROOmkJBiMGdPiGwkrsGRJ8n168MFkXV14IXzjG8n3uRivvfbxoDBvXpIG0K4dHHrox3eKBg2CDh2arTkNBQAiotU8hg0bFhYR69dHPPJIxBlnRHTuHJFsllv2sffeEUcfHXHZZRH33huxfHlETU3Lfxbvvx8xaVJEly4R7dpFXHRRxNq1LV+PhrzySsQ110R84hPJ53bQQRE33RTx6qtb81RXR8yZE3HxxRFlZUm+Ll0izjor4tFHIzZsKFn1M2fu3IjPf37rOrjiiqb5Pm3eHFFZmfxur7km4sQTI3r12vp76tAhIpdLvgM//WnEokURmzbt+vumgHzUs031EUBr8dFH8MQTyR7Jo4/Cu+8mJ0nHj2/5roM+fZLD2t3pJOzrr8OkSUnXyl57wde/nuyxde3a8nWpqYGZM+HOO+Gxx5Kf+Oc+BxdfDCeemOwBNqS6GubMSdbzr36VdC90754c4Zx+OowcmeyRWtOJgFmz4KabYPZs6NULvvpVuOSSpAuzOd/35Ze3dhvVPt59N5m/995w2GFbj6hPOmmn6+MjgNZo06aImTMjLrggomfPZE+hR4+I88+PePzxiI8+KnUNdz/PPx9x2mnJZ7XPPhF33NFyn9Orr0ZMnpzs5UPEvvsme3svv7xz5X30UcRjj0Wcd15Et25Jmb17R3zpSxFPPpkcOdjOq6lJ9siPOCL5bP/mbyK+//2I994rbZ0qKiLuuy/ia1+L+PSnIzp1SupXUbHTxdLAEUDJN+o78shEAKiujnjqqYgvfzmiT59kFXXtGnHOORG/+U3Exo2lrmHr8PTTEccck3x+/ftHPPRQchje1DZvjpg9O+KLX4xo3z55v+OOi5g+vWkDz4YNSXfQWWclXRO1Ae4rX4n4wx9K0/3WWm3alHRbDhiQfI6f+lTElCm7b1dbdXXEkiW7tI4dAHZnNTUR//3fEZdeurWvuFOniNNPj/jVr5I+f9txmzdHzJix9Yc+fHjEH//YNGWvWxfxwx9GHHxwUnbPnske21/+0jTlb8+HHyYB7bTTknMxtXuvl12W9GE3R6BrC9avj7jzzoi+fZPP7NBDI37xiybta99dOQDsbjZvjnjmmYjLL48oL09WxV57RZx6asSDDyYnN61pbNoU8ZOfJBtJiDj55IjnntvxcjZvjvjzn5MuuNoN71FHRUyblmyUS+G99yLuvz9i7NjkRGLtieZvfjMin3cwiIh4992I731v687VUUclOwYZOmpyANgdbN4c8eyzEd/6VkS/fsnH3759ctXBz3+efFGt+XzwQdJH37VrxB57JH3pq1c3vtz770fcdVfE4Ycn66xz54iJE5N1uTt5++2Iu++OGDMmYs89Y0v3xtVXJ1eVZC0YvPFGxHe+s/X82Wc/m3SvZu1ziIYDQDauAvrOd5Kbk3r1Ss6i9+y5dbruc48eTX91y7Jl8MADyZUdL7yQXAXy2c8mV3WMG9e8VxrYtqqq4MYbk6t09twz+X+hK66Abt0+nm/ZsuS6/XvuSa7MOPTQ5Eqec87ZNu/uZt06eOSR5Dv31FPJlUkHH5y0YXvf/9rprl1b7x3Wde/aPeWU5K9Ejjii1DUrmWzfCHb55cllXm+9lfwwPvhg+/m7dav/R9FYWrduW380zz+f/PgefDDZkOyxB4wYkWz0Tz01uZTSSmvlSrjmmiQ49+mT7ChMmAC/+U2y4f+v/0puzvniF+Gii+Af/7F1bhSrquDhh5OAsGpV8ht4663k0uKGtGu37fe8mMDRs2fpbmB78cXkrt1p07betfutb8HAgaWpz25klwKApFHA/wPaAT+JiFvqzD8QuBvokea5MiIeS+ddRTJmcA3wfyJiZjFl1qfJ7gP46CN4++2tP4Ta58LphuZt70ezxx7JD6BTp+SHJsGnP51s9MePh098Ytfrbk0vn0+OAGbPTjZ8NTXwqU8lG/0JE9pmsI6A9esb/r5v7zfx1lvJ8g3p2DH5HXTvnvwmWqo9FRXJPRIXXADf/Gbxd+1mwE4HAEntgOeB40kGiJ8HnBkRzxXkmQIsiIg7JQ0AHouIvun0/SQDvv8N8CTwd+li2y2zPiW/EayhH03dH8m77yY3bpx2Guy/f+nqa8WLgMcfh9/9LvmDuZEjW27j1dps3px8x7cXOGp/By3Zw9C/P1x6aXF/LJgxDQWAYjq7jwRWRMTKtKAHgLFA4cY6gNpO0e7AmnR6LPBARGwEXpK0Ii2PIsrc/UjJ3n2nTskfmlnbISV/yjZ6dKlrsvvbY4/kXFmPHt7LbuWK2cXZH1hV8LoyTSt0PXCOpErgMeDSRpYtpkwAJE2UlJeUr6qqKqK6ZmZWjGICQH1nveoe150JTIuIcmAMcK+kPbazbDFlJokRUyIiFxG5srKyIqprZmbFKKYLqBI4oOB1OVu7eGpdCIwCiIi5kjoCfRpZtrEyzcysGRVzBDAP6C+pn6QOwBnAjDp5/gqMBJB0CNARqErznSFpL0n9gP7An4ss08zMmlGjRwARUS3pEmAmySWbUyNimaRJJHeXzQC+Dtwl6WskXTkT0rvPlkmaTnJytxr414ioAaivzGZon5mZNWEzkWIAAAQaSURBVCAbN4KZmWVYQ5eB+kJnM7OMcgAwM8uoVtUFJKkKeKXU9ShSH+CNUleimbhtrVdbbp/b1rCDImKb6+hbVQBoTSTl6+tzawvcttarLbfPbdtx7gIyM8soBwAzs4xyAGg+U0pdgWbktrVebbl9btsO8jkAM7OM8hGAmVlGOQCYmWWUA0ATkPSypCWSFkrKp2m9JD0h6YX0udWM/C5pqqTXJS0tSKu3PUrcJmmFpMWSDi9dzRvXQNuul7Q6XX8LJY0pmHdV2rYKSSeWptbFkXSApNmSlktaJumyNL3Vr7vttK2trLuOkv4saVHavu+m6f0kPZOuuwfTP88k/YPNB9P2PSOp7069cUT4sYsP4GWgT52075GMjQxwJfBvpa7nDrTnGOBwYGlj7SEZ/+H3JGM8DAeeKXX9d6Jt1wPfqCfvAGARsBfQD3gRaFfqNmynbfsBh6fTXUmGXR3QFtbddtrWVtadgC7pdHvgmXSdTAfOSNN/DFycTn8F+HE6fQbw4M68r48Ams9Y4O50+m5gXAnrskMi4o/AujrJDbVnLHBPJJ4GekjabQdlbaBtDdkypGlEvAQUDmm624mItRHxbDr9HrCcZKS9Vr/uttO2hrS2dRcR8X76sn36COA44KE0ve66q12nDwEjJdU30NZ2OQA0jQD+U9J8SRPTtH0jYi0kX15gn5LVrmk01J6ih/fczV2SdoNMLeiua7VtS7sEDiPZk2xT665O26CNrDtJ7SQtBF4HniA5ank7IqrTLIVt2NK+dP47QO8dfU8HgKZxdEQcDowG/lXSMaWuUAsqenjP3didwKeAocBa4P+m6a2ybZK6AA8DX42Id7eXtZ603bp99bStzay7iKiJiKEkIyQeCRxSX7b0uUna5wDQBCJiTfr8OvAIycp7rfZwOn1+vXQ1bBINtaeYIUN3axHxWvrj2wzcxdauglbXNkntSTaQ90XEr9LkNrHu6mtbW1p3tSLibWAOyTmAHpJqB+4qbMOW9qXzu1N81+YWDgC7SFJnSV1rp4ETgKUkQ1yel2Y7D3i0NDVsMg21ZwZwbnpFyXDgndruhtaiTr/3KSTrDxoe0nS3lPYB/xRYHhHfL5jV6tddQ21rQ+uuTFKPdHpv4LMk5zlmA19Is9Vdd7Xr9AvAU5GeEd4hpT773dofwCdJrjZYBCwDrknTewOzgBfS516lrusOtOl+ksPpTSR7Ghc21B6SQ9E7SPorlwC5Utd/J9p2b1r3xekPa7+C/NekbasARpe6/o207dMk3QCLgYXpY0xbWHfbaVtbWXeDgQVpO5YC30nTP0kSuFYAvwT2StM7pq9XpPM/uTPv67+CMDPLKHcBmZlllAOAmVlGOQCYmWWUA4CZWUY5AJiZZZQDgJlZRjkAmJll1P8CX39nnnXttS0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model1.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[169,   8,   1],\n",
       "       [ 13, 130,  40],\n",
       "       [  5,  34, 130]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importances(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données non-équilibrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20],\n",
       "                                        'n_estimators': [25, 50, 75, 100, 125,\n",
       "                                                         150, 175, 200, 225,\n",
       "                                                         250, 275, 300]})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, n_estimators=150)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.3341062068939209s\n",
      "inference time: 0.0219724178314209s\n",
      "test score :  0.7916666666666666\n",
      "train: 0.7495948136142626\n"
     ]
    }
   ],
   "source": [
    "model = search.best_estimator_\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train2, y_train2)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "start = time.time()\n",
    "test_score = model.score(X_val1,y_val1)\n",
    "stop = time.time()\n",
    "print(f\"inference time: {stop - start}s\")\n",
    "print(\"test score : \", test_score)\n",
    "print(\"train:\", model.score(X_train1, y_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    model2 = model.fit(X_train2, y_train2)\n",
    "    accuracy_train.append(model.score(X_train2, y_train2))\n",
    "    accuracy_test.append(model.score(X_val1, y_val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.plot(n_estimators, accuracy_train, '-b', label='acc_train')\n",
    "pylab.plot(n_estimators, accuracy_test, '-r', label='acc_test')\n",
    "pylab.legend(loc='upper left')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   6,   2],\n",
       "       [  0, 111,  38],\n",
       "       [  0,  24, 155]], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = model2.predict(X_val1)\n",
    "confusion_matrix(y_val1, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importances(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
